{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, roc_auc_score, f1_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.v2 as v2\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import utils\n",
    "from torch.utils.data import random_split\n",
    "import pytorch_grad_cam\n",
    "import torch.hub as hub\n",
    "from torchvision.transforms.v2 import functional as F\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "seed = 42 # set by user\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.random.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "channels = 2 # without blue channel\n",
    "batch_size = 32 # set by user\n",
    "baseline = False # whether to use baseline model: VGG-16, DenseNet-121,ResNet-50, efficientnet_v2_small, convnext_base\n",
    "baseline_model = ['densenet121'] # baseline model can input 'densenet121', 'efficientnet_v2_s', 'resnet50', 'vgg16', 'convnext_base'\n",
    "early_stop_mode = 'accuracy'  # choose 'loss' mode, 'accuracy' mode, 'loss or accuracy' mode or 'loss and accuracy' modes\n",
    "# Number of variations to generate per image\n",
    "num_variations_per_image_0 = 4\n",
    "num_variations_per_image_1 = 4\n",
    "test_percent = 0.15  # choose the proportion size of test set\n",
    "validation_percent = 0.1  # choose the proportion size of validation set if close the cross validation\n",
    "cross_validation = True  # choose open or close Cross-Validation\n",
    "fold_num = 5  # choose the number of fold if open the cross-validation\n",
    "run_name = 'cell_classification_without_nucleus' # log name\n",
    "if not cross_validation:\n",
    "    fold_num = 1\n",
    "finetune = True # choose to whether fine-tuning the features from the backbone\n",
    "main_structure = 'dino' # choose 'dino', 'vit', 'dinov2', 'dinov3'\n",
    "\n",
    "dataset_autoseg_noblue_path = \"D:\\\\cell_40x_noblue\"\n",
    "train_autoseg_noblue_path = \"D:\\\\cell_autoseg_train_noblue\\split\"\n",
    "train_autoseg_noblue_cancer_path = 'D:\\\\cell_autoseg_train_noblue\\split\\\\cancer\\\\'\n",
    "train_autoseg_noblue_normal_path = 'D:\\\\cell_autoseg_train_noblue\\split\\\\normal\\\\'\n",
    "train_autoseg_noblue_cv_path = 'D:\\\\cell_autoseg_train_noblue\\\\cross validation\\\\'\n",
    "test_autoseg_noblue_path = 'D:\\\\cell_autoseg_test_noblue\\split'\n",
    "test_whole_autoseg_noblue_path = 'D:\\\\cell_autoseg_test_noblue\\whole\\\\'\n",
    "test_autoseg_noblue_cancer_path = \"D:\\\\cell_autoseg_test_noblue\\split\\\\cancer\\\\\"\n",
    "test_autoseg_noblue_normal_path = 'D:\\\\cell_autoseg_test_noblue\\split\\\\normal\\\\'\n",
    "validation_autoseg_noblue_path = 'D:\\\\cell_autoseg_validation_noblue\\split'\n",
    "validation_whole_autoseg_noblue_path = 'D:\\\\cell_autoseg_validation_noblue\\whole\\\\'\n",
    "validation_autoseg_noblue_cancer_path = 'D:\\\\cell_autoseg_validation_noblue\\split\\\\cancer\\\\'\n",
    "validation_autoseg_noblue_normal_path = 'D:\\\\cell_autoseg_validation_noblue\\split\\\\normal\\\\'\n",
    "validation_autoseg_noblue_cv_path = 'D:\\\\cell_autoseg_validation_noblue\\\\cross validation\\\\'\n",
    "REPO_DINOV3= \"D:\\cell_classification_pythonprojects\\dinov3\\dinov3\"\n",
    "WEIGHTS_DINOV3 = \"D:\\cell_classification_pythonprojects\\My_model\\dinov3_vitb16_pretrain_lvd1689m-73cec8be.pth\"\n",
    "grad_cam_base_path = \"D:\\cell_image_XAI\\\\cell_40x\""
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "SCRIPT_DIR = Path(__file__).resolve().parent if \"__file__\" in globals() else Path.cwd()\n",
    "log_file = SCRIPT_DIR / f\"{run_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n",
    "logger = logging.getLogger(run_name)\n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.propagate = False\n",
    "for h in logger.handlers[:]:\n",
    "    try:\n",
    "        h.flush()\n",
    "    except Exception:\n",
    "        pass\n",
    "    h.close()\n",
    "    logger.removeHandler(h)\n",
    "\n",
    "fmt = logging.Formatter(\"%(asctime)s | %(levelname)s | %(message)s\")\n",
    "\n",
    "sh = logging.StreamHandler()\n",
    "sh.setFormatter(fmt)\n",
    "logger.addHandler(sh)\n",
    "\n",
    "fh = logging.FileHandler(log_file, mode='a', encoding=\"utf-8\")\n",
    "fh.setFormatter(fmt)\n",
    "logger.addHandler(fh)"
   ],
   "id": "7e5e350a0371770c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# image process",
   "id": "5a518efee6e941e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from training_toolbox import ResizeWithPadding\n",
    "\n",
    "\n",
    "transform = v2.Compose([ResizeWithPadding((224,224)), v2.ToTensor()])\n",
    "# resize and transfer to tensor\n",
    "dataset = torchvision.datasets.ImageFolder(dataset_autoseg_noblue_path, transform=transform)  # read data\n",
    "# Assuming images are organized in subdirectories where each subdirectory name is the class label\n",
    "# 0 is cancer, 1 is normal\n",
    "\n",
    "transform_augmented = v2.Compose([v2.RandomHorizontalFlip(),\n",
    "                                  v2.RandomVerticalFlip(),\n",
    "                                  v2.RandomRotation(degrees=40),\n",
    "                                  v2.RandomAffine(degrees=40, translate=(0.1, 0.1), shear=(-8,8,-8,8), scale=(0.9, 1.1)),\n",
    "                                  ])  # Image Augmented Transformation"
   ],
   "id": "ef3479261384721d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "image_paths = []\n",
    "image_labels = []\n",
    "for i in dataset.samples:\n",
    "    image_paths.append(i[0])\n",
    "    image_labels.append(i[1])\n",
    "\n",
    "# split dataset into test set and (train set + validation set)\n",
    "train_val_paths, test_paths, train_val_labels, test_labels = train_test_split(\n",
    "    image_paths, image_labels, test_size=test_percent, stratify=image_labels, random_state=seed)\n",
    "\n",
    "logger.info(\n",
    "    f'we have {train_val_labels.count(0)} cancer cells and {train_val_labels.count(1)} normal cells, {len(train_val_labels)} cells in total, for training and validating')\n",
    "logger.info(\n",
    "    f'we have {test_labels.count(0)} cancer cells and {test_labels.count(1)} normal cells, {len(test_paths)} cells in total, for testing')\n",
    "\n",
    "# save the test image to target folders\n",
    "for i in range(len(test_paths)):\n",
    "    for j in range(len(dataset.samples)):\n",
    "        if dataset.samples[j][0] == test_paths[i] and dataset.samples[j][1] == 0:\n",
    "            utils.save_image(dataset[j][0],\n",
    "                             test_autoseg_noblue_cancer_path + test_paths[i].split('\\\\')[-1].split('.')[0] + \"_test.png\")\n",
    "            break\n",
    "        elif dataset.samples[j][0] == test_paths[i] and dataset.samples[j][1] == 1:\n",
    "            utils.save_image(dataset[j][0],\n",
    "                             test_autoseg_noblue_normal_path + test_paths[i].split('\\\\')[-1].split(\".\")[0] + \"_test.png\")\n",
    "            break"
   ],
   "id": "af0505c1a9a67770"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from training_toolbox import compute_mean_std_noblue\n",
    "\n",
    "# train and validation dataset for calculating the image mean and std for normalization\n",
    "train_val_dataset = []\n",
    "for i in range(len(train_val_paths)):\n",
    "    for j in range(len(dataset.samples)):\n",
    "        if dataset.samples[j][0] == train_val_paths[i]:\n",
    "            train_val_dataset.append(dataset[j][0])\n",
    "            break\n",
    "\n",
    "if finetune:\n",
    "    images_mean, images_std = compute_mean_std_noblue(train_val_dataset, channels)\n",
    "else:\n",
    "    images_mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "    images_std = torch.tensor([0.229, 0.224, 0.225])\n",
    "logger.info(f\"Mean: {images_mean}\")\n",
    "logger.info(f\"Std: {images_std}\")\n",
    "\n",
    "# inverse_transform, to restore the images when saving them to whole folder and displaying them in XAI\n",
    "transform_inverse = v2.Compose([v2.Normalize(\n",
    "    mean=[-images_mean[0] / images_std[0], -images_mean[1] / images_std[1], -images_mean[2] / images_std[2]],\n",
    "    std=[1 / images_std[0], 1 / images_std[1], 1 / images_std[2]])])  # when mean = images_mean and std = images_std"
   ],
   "id": "c6ff09619c64e529"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from training_toolbox import save_validation_images, generate_save_train_images, read_data, save_whole_image\n",
    "\n",
    "# This transform: to tensor and normalization is used for all images\n",
    "transform_whole_dataset = v2.Compose([v2.ToTensor(), v2.Normalize(mean=images_mean, std=images_std)])\n",
    "\n",
    "if not cross_validation:\n",
    "    # split train_val_dataset into train set and validation set\n",
    "    train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "        train_val_paths, train_val_labels, test_size=validation_percent / (1 - test_percent), stratify=train_val_labels,\n",
    "        random_state=seed) # here is a shuffle\n",
    "\n",
    "    logger.info(f'The cross validation openness is closed')\n",
    "    logger.info(\n",
    "        f'we have {train_labels.count(0)} cancer cells and {train_labels.count(1)} normal cells, {len(train_paths)} cells in total, for training')\n",
    "    logger.info(\n",
    "        f'we have {val_labels.count(0)} cancer cells and {val_labels.count(1)} normal cells, {len(val_paths)} cells in total, for validating')\n",
    "\n",
    "    save_validation_images(val_paths, dataset, validation_autoseg_noblue_cancer_path, validation_autoseg_noblue_normal_path)\n",
    "    generate_save_train_images(train_paths, dataset, train_autoseg_noblue_cancer_path, train_autoseg_noblue_normal_path, num_variations_per_image_0, num_variations_per_image_1, transform_augmented, logger)\n",
    "\n",
    "    # read test, train, validate data from target folders\n",
    "    test_dataset = []\n",
    "    val_dataset = []\n",
    "    train_dataset = []\n",
    "    test, val, train = read_data(test_autoseg_noblue_path, validation_autoseg_noblue_path, train_autoseg_noblue_path, transform_whole_dataset)\n",
    "    test_dataset.append(test)\n",
    "    val_dataset.append(val)\n",
    "    train_dataset.append(train)\n",
    "\n",
    "    save_whole_image(val, test, validation_whole_autoseg_noblue_path, test_whole_autoseg_noblue_path, transform_inverse)\n",
    "else:\n",
    "    logger.info(f'The cross validation openness is opened')\n",
    "    test_dataset = []\n",
    "    val_dataset = []\n",
    "    train_dataset = []\n",
    "    skf = StratifiedKFold(n_splits=fold_num, shuffle=True, random_state=seed)\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(train_val_paths, train_val_labels)):\n",
    "        # use Stratified K-fold cross validation to create e.g. 10 folds, in each fold, the ratio between normal and cancer approximately keeping the same as the ratio in original image dataset.\n",
    "        train_paths = [train_val_paths[i] for i in train_idx]\n",
    "        train_labels = [train_val_labels[i] for i in train_idx]\n",
    "\n",
    "        val_paths = [train_val_paths[i] for i in val_idx]\n",
    "        val_labels = [train_val_labels[i] for i in val_idx]\n",
    "\n",
    "        logger.info(f\"In fold {fold}\")\n",
    "        logger.info(\n",
    "        f'we have {train_labels.count(0)} cancer cells and {train_labels.count(1)} normal cells, {len(train_paths)} cells in total, for training')\n",
    "        logger.info(\n",
    "        f'we have {val_labels.count(0)} cancer cells and {val_labels.count(1)} normal cells, {len(val_paths)} cells in total, for validating')\n",
    "\n",
    "        # new folders to save validation images for each fold.\n",
    "        validation_cv_fold_path = validation_autoseg_noblue_cv_path + \"cross validation \" + str(fold)\n",
    "        validation_cv_fold_split_path = validation_autoseg_noblue_cv_path + \"cross validation \" + str(fold) + '\\\\split'\n",
    "        validation_cv_fold_whole_path = validation_autoseg_noblue_cv_path + \"cross validation \" + str(fold) + '\\\\whole'\n",
    "        validation_cv_fold_split_cancer_path = validation_autoseg_noblue_cv_path + \"cross validation \" + str(fold) + '\\\\split\\\\cancer'\n",
    "        validation_cv_fold_split_normal_path = validation_autoseg_noblue_cv_path + \"cross validation \" + str(fold) + '\\\\split\\\\normal'\n",
    "        os.makedirs(validation_cv_fold_path, exist_ok=True)\n",
    "        os.makedirs(validation_cv_fold_split_path, exist_ok=True)\n",
    "        os.makedirs(validation_cv_fold_whole_path, exist_ok=True)\n",
    "        os.makedirs(validation_cv_fold_split_cancer_path, exist_ok=True)\n",
    "        os.makedirs(validation_cv_fold_split_normal_path, exist_ok=True)\n",
    "\n",
    "        save_validation_images(val_paths, dataset, validation_cv_fold_split_cancer_path + '\\\\', validation_cv_fold_split_normal_path + '\\\\')\n",
    "\n",
    "        # new folders to save train images for each fold.\n",
    "        train_cv_fold_path = train_autoseg_noblue_cv_path + \"cross validation \" + str(fold)\n",
    "        train_cv_fold_split_path = train_autoseg_noblue_cv_path + \"cross validation \" + str(fold) + '\\\\split'\n",
    "        train_cv_fold_whole_path = train_autoseg_noblue_cv_path + \"cross validation \" + str(fold) + '\\\\whole'\n",
    "        train_cv_fold_split_cancer_path = train_autoseg_noblue_cv_path + \"cross validation \" + str(fold) + '\\\\split\\\\cancer'\n",
    "        train_cv_fold_split_normal_path = train_autoseg_noblue_cv_path + \"cross validation \" + str(fold) + '\\\\split\\\\normal'\n",
    "        os.makedirs(train_cv_fold_path, exist_ok=True)\n",
    "        os.makedirs(train_cv_fold_split_path, exist_ok=True)\n",
    "        os.makedirs(train_cv_fold_whole_path, exist_ok=True)\n",
    "        os.makedirs(train_cv_fold_split_cancer_path, exist_ok=True)\n",
    "        os.makedirs(train_cv_fold_split_normal_path, exist_ok=True)\n",
    "\n",
    "        generate_save_train_images(train_paths, dataset, train_cv_fold_split_cancer_path + '\\\\', train_cv_fold_split_normal_path + '\\\\', num_variations_per_image_0, num_variations_per_image_1, transform_augmented, logger)\n",
    "\n",
    "        # read test, train, validate data from target folders\n",
    "        test, val, train = read_data(test_autoseg_noblue_path, validation_cv_fold_split_path, train_cv_fold_split_path, transform_whole_dataset)\n",
    "        test_dataset.append(test)\n",
    "        val_dataset.append(val)\n",
    "        train_dataset.append(train)\n",
    "\n",
    "        save_whole_image(val, test, validation_cv_fold_whole_path + '\\\\', test_whole_autoseg_noblue_path, transform_inverse)"
   ],
   "id": "c0dbc6b266f6ce46"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model training",
   "id": "cd7153cc70c5be86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch import nn, optim\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.models import ViT_B_16_Weights\n",
    "from training_toolbox import replace_classifier, get_cosine_with_warmup_tail, plot_loss_curves, inspect_model_and_optimizer\n",
    "\n",
    "if not baseline:\n",
    "    logger.info(\"#####################################################################\")\n",
    "    logger.info(f'Using model: {main_structure}')\n",
    "    logger.info(\"#####################################################################\")\n",
    "    if finetune:\n",
    "        param_grid = {\n",
    "        'lr_backbone': [0.00002, 0.0001],\n",
    "        'lr_head': [0.0002, 0.001],\n",
    "        'weight_decay_backbone': [0.01, 0.001],\n",
    "        'weight_decay_head': [0.000],\n",
    "        'dropout_p': [0.3],\n",
    "        'warmup_epoch': [5],\n",
    "        'lr_decay_epoch': [40],\n",
    "        'unfrozen_blocks': [[0,1,2,3,4,5,6,7,8,9,10,11]],\n",
    "        'grad_clip': [False],\n",
    "        'label_smoothing': [0.0]\n",
    "        }\n",
    "    else:\n",
    "        param_grid = {\n",
    "        'lr_backbone': [0.00002],\n",
    "        'lr_head': [0.0002, 0.001],\n",
    "        'weight_decay_backbone': [0.01],\n",
    "        'weight_decay_head': [0.000, 0.001],\n",
    "        'dropout_p': [0.3, 0.0],\n",
    "        'warmup_epoch': [5],\n",
    "        'lr_decay_epoch': [40],\n",
    "        'unfrozen_blocks': [[0,1,2,3,4,5,6,7,8,9,10,11]],\n",
    "        'grad_clip': [False],\n",
    "        'label_smoothing': [0.0]\n",
    "        }\n",
    "    grid = list(ParameterGrid(param_grid)) # generate all the hyper-parameter combination\n",
    "    gird_search_result = [] # store the cross-validation performance of each hyper-parameter set\n",
    "    for set_num, hyper_params in enumerate(grid):\n",
    "\n",
    "        config = {\n",
    "        'lr_backbone': hyper_params['lr_backbone'],\n",
    "        'lr_head': hyper_params['lr_head'],\n",
    "        'weight_decay_backbone': hyper_params['weight_decay_backbone'],\n",
    "        'weight_decay_head': hyper_params['weight_decay_head'],\n",
    "        'dropout_p': hyper_params['dropout_p'],\n",
    "        'num_epochs': 60,\n",
    "        'warmup_epoch': hyper_params['warmup_epoch'],\n",
    "        'lr_decay_epoch': hyper_params['lr_decay_epoch'],\n",
    "        'unfrozen_blocks': hyper_params['unfrozen_blocks'],\n",
    "        'grad_clip': hyper_params['grad_clip'],\n",
    "        'label_smoothing': hyper_params['label_smoothing']\n",
    "        } # configure all the hyper-parameters, including not for grid search\n",
    "\n",
    "        logger.info(f\"Running config {set_num + 1}/{len(grid)}: {config}\")\n",
    "\n",
    "        for fold in range(fold_num):\n",
    "            logger.info('###############################################')\n",
    "            logger.info(f'This is the fold: {fold}')\n",
    "            logger.info('###############################################')\n",
    "\n",
    "            g = torch.Generator()\n",
    "            g.manual_seed(42 + fold)\n",
    "\n",
    "            # Load the train, validate, and test dataset, ensure the sequences of training samples in the same fold of different hyperparameter sets to keep same.\n",
    "            train_loader = DataLoader(train_dataset[fold], batch_size=batch_size, shuffle=True, generator=g, pin_memory=True)\n",
    "            val_loader = DataLoader(val_dataset[fold], batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "            test_loader = DataLoader(test_dataset[fold], batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "\n",
    "            # Set gpu/cpu\n",
    "            logger.info(f\"Use device: {device}\")\n",
    "\n",
    "            if main_structure.lower() == 'dino':\n",
    "                model = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16', pretrained=True)\n",
    "                num_features = model.embed_dim\n",
    "            elif main_structure.lower() == 'dinov2':\n",
    "                model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14', pretrained=True)\n",
    "                num_features = model.embed_dim\n",
    "            elif main_structure.lower() == 'dinov3':\n",
    "                model = torch.hub.load(REPO_DINOV3, 'dinov3_vitb16', source='local', weights=WEIGHTS_DINOV3)\n",
    "                num_features = model.embed_dim\n",
    "            elif main_structure.lower() == 'vit':\n",
    "                model = torch.hub.load('pytorch/vision', 'vit_b_16', pretrained=True)\n",
    "                model, num_features = replace_classifier(model)\n",
    "            model = model.to(device)\n",
    "\n",
    "\n",
    "            class ModifiedViT(nn.Module):\n",
    "                def __init__(self, base_model, in_features):\n",
    "                    super(ModifiedViT, self).__init__()\n",
    "                    self.base_model = base_model\n",
    "                    self.head = nn.Sequential(nn.Dropout(config['dropout_p']),\n",
    "                                              nn.Linear(in_features, 2))  # modify the head from Identify to 2-class classification (Linear Layer) and add drop out (included in grid search)\n",
    "\n",
    "                def forward(self, x):\n",
    "                    # the features from ViT backbone (batch size, 768 (dim of class token))\n",
    "                    features = self.base_model(x)\n",
    "                    # pass the classification head\n",
    "                    return self.head(features)\n",
    "\n",
    "\n",
    "            model = ModifiedViT(model, num_features).to(device)\n",
    "\n",
    "            if finetune:\n",
    "                if main_structure.lower() == 'vit':\n",
    "                    for param in model.base_model.encoder.layers.parameters():\n",
    "                        param.requires_grad = False\n",
    "                    for layer_index in config['unfrozen_blocks']:\n",
    "                        layer = model.base_model.encoder.layers[layer_index]\n",
    "                        # only un-froze the last few layers (included in grid search)\n",
    "                        for param in layer.parameters():\n",
    "                            param.requires_grad = True\n",
    "                else:\n",
    "                    for param in model.base_model.blocks.parameters():\n",
    "                        param.requires_grad = False\n",
    "                    for layer_index in config['unfrozen_blocks']:\n",
    "                        layer = model.base_model.blocks[layer_index]\n",
    "                        # only un-froze the last few layers (included in grid search)\n",
    "                        for param in layer.parameters():\n",
    "                            param.requires_grad = True\n",
    "                for param in model.head.parameters(): # un froze the classification head\n",
    "                    param.requires_grad = True\n",
    "            else:\n",
    "                for param in model.parameters():\n",
    "                    param.requires_grad = False\n",
    "                for param in model.head.parameters(): # un froze the classification head\n",
    "                    param.requires_grad = True\n",
    "\n",
    "\n",
    "            class EarlyStopping:\n",
    "                def __init__(self, patience=5, mode='loss', min_delta=0.0, fold=0, epoch_number = 10, name = None, hyper_index = 0):\n",
    "                    self.patience = patience\n",
    "                    self.mode = mode\n",
    "                    self.fold = fold\n",
    "                    self.min_delta = min_delta\n",
    "                    self.counter = 0\n",
    "                    self.epoch_number = epoch_number\n",
    "                    self.name = name\n",
    "                    self.hyper_index = hyper_index\n",
    "                    self.best = None\n",
    "                    self.early_stop = False\n",
    "\n",
    "                def __call__(self, val_loss, accuracy, epoch):\n",
    "                    logger.info(\"the mode of early stopping is \" + self.mode)\n",
    "                    if self.mode == 'loss':\n",
    "                        if self.best is None:\n",
    "                            logger.info(f\"This is the first epoch {epoch + 1}!\")\n",
    "                            self.best = val_loss\n",
    "                            torch.save(model.state_dict(), self.name + \"_best_model_parameter_\" + str(self.hyper_index) + \"_\" + str(self.fold) + \".pth\")\n",
    "                            logger.info(f\"The best val_loss is: {self.best}\")\n",
    "                        elif val_loss < self.best - self.min_delta:\n",
    "                            logger.info(f\"Epoch {epoch + 1} Early Stop Check Pass!\")\n",
    "                            self.best = val_loss\n",
    "                            self.counter = 0\n",
    "                            torch.save(model.state_dict(), self.name + \"_best_model_parameter_\" + str(self.hyper_index) + \"_\" + str(self.fold) + \".pth\")\n",
    "                            logger.info(f\"The best val_loss is: {self.best}\")\n",
    "                        else:\n",
    "                            self.counter += 1\n",
    "                            logger.info(\n",
    "                                f\"Epoch {epoch + 1} not pass the Early Stopping! EarlyStopping counter: {self.counter} / {self.patience}\")\n",
    "                            logger.info(f\"The best val_loss is still: {self.best}\")\n",
    "                            if self.counter >= self.patience or (epoch + 1) == self.epoch_number:\n",
    "                                self.early_stop = True\n",
    "                    elif self.mode == 'accuracy':\n",
    "                        if self.best is None:\n",
    "                            logger.info(f\"This is the first epoch {epoch + 1}!\")\n",
    "                            self.best = [val_loss, accuracy]\n",
    "                            torch.save(model.state_dict(), self.name + \"_best_model_parameter_\" + str(self.hyper_index) + \"_\" + str(self.fold) + \".pth\")\n",
    "                            logger.info(f\"The best accuracy / weighted f1 score is: {self.best[1]}\")\n",
    "                        elif accuracy > self.best[1]:\n",
    "                            logger.info(f\"Epoch {epoch + 1} Early Stop Check Pass!\")\n",
    "                            self.best = [val_loss, accuracy]\n",
    "                            self.counter = 0\n",
    "                            torch.save(model.state_dict(), self.name + \"_best_model_parameter_\" + str(self.hyper_index) + \"_\" + str(self.fold) + \".pth\")\n",
    "                            logger.info(f\"The best accuracy / weighted f1 score is: {self.best[1]}\")\n",
    "                        elif accuracy == self.best[1] and val_loss < self.best[0]:\n",
    "                            logger.info(f\"Epoch {epoch + 1} Early Stop Check Pass! val_loss is smaller although the accuracy / weighted f1 score keeps the same.\")\n",
    "                            self.best = [val_loss, accuracy]\n",
    "                            self.counter = 0\n",
    "                            torch.save(model.state_dict(), self.name + \"_best_model_parameter_\" + str(self.hyper_index) + \"_\" + str(self.fold) + \".pth\")\n",
    "                            logger.info(f\"The best accuracy / weighted f1 score is: {self.best[1]}\")\n",
    "                        else:\n",
    "                            self.counter += 1\n",
    "                            logger.info(\n",
    "                                f\"Epoch {epoch + 1} not pass the Early Stopping! EarlyStopping counter: {self.counter} / {self.patience}\")\n",
    "                            logger.info(f\"The best accuracy / weighted f1 score is still: {self.best[1]}\")\n",
    "                            if self.counter >= self.patience or (epoch + 1) == self.epoch_number:\n",
    "                                self.early_stop = True\n",
    "                    elif self.mode == 'loss and accuracy':\n",
    "                        if self.best is None:\n",
    "                            logger.info(f\"This is the first epoch {epoch + 1}!\")\n",
    "                            self.best = [val_loss, accuracy]\n",
    "                            torch.save(model.state_dict(), self.name + \"_best_model_parameter_\" + str(self.hyper_index) + \"_\" + str(self.fold) + \".pth\")\n",
    "                            logger.info(f\"The best val_loss and accuracy / weighted f1 score are: {self.best[0]}, {self.best[1]}\")\n",
    "                        elif val_loss < self.best[0] - self.min_delta and accuracy > self.best[1]:\n",
    "                            logger.info(f\"Epoch {epoch + 1} Early Stop Check Pass!\")\n",
    "                            self.best = [val_loss, accuracy]\n",
    "                            self.counter = 0\n",
    "                            torch.save(model.state_dict(), self.name + \"_best_model_parameter_\" + str(self.hyper_index) + \"_\" + str(self.fold) + \".pth\")\n",
    "                            logger.info(f\"The best val_loss and accuracy / weighted f1 score are: {self.best[0]}, {self.best[1]}\")\n",
    "                        else:\n",
    "                            self.counter += 1\n",
    "                            logger.info(\n",
    "                                f\"Epoch {epoch + 1} not pass the Early Stopping! EarlyStopping counter: {self.counter} / {self.patience}\")\n",
    "                            logger.info(f\"The best val_loss and accuracy / weighted f1 score are still: {self.best[0]}, {self.best[1]}\")\n",
    "                            if self.counter >= self.patience or (epoch + 1) == self.epoch_number:\n",
    "                                self.early_stop = True\n",
    "                    elif self.mode == 'loss or accuracy':\n",
    "                        if self.best is None:\n",
    "                            logger.info(f\"This is the first epoch {epoch + 1}!\")\n",
    "                            self.best = [val_loss, accuracy]\n",
    "                            torch.save(model.state_dict(), self.name + \"_best_model_parameter_\" + str(self.hyper_index) + \"_\" + str(self.fold) + \".pth\")\n",
    "                            logger.info(f\"The best val_loss and accuracy / weighted f1 score are: {self.best[0]}, {self.best[1]}\")\n",
    "                        elif val_loss < self.best[0] - self.min_delta or accuracy > self.best[1]:\n",
    "                            logger.info(f\"Epoch {epoch + 1} Early Stop Check Pass!\")\n",
    "                            self.best = [val_loss, accuracy]\n",
    "                            self.counter = 0\n",
    "                            torch.save(model.state_dict(), self.name + \"_best_model_parameter_\" + str(self.hyper_index) + \"_\" + str(self.fold) + \".pth\")\n",
    "                            logger.info(f\"The best val_loss and accuracy / weighted f1 score are: {self.best[0]}, {self.best[1]}\")\n",
    "                        else:\n",
    "                            self.counter += 1\n",
    "                            logger.info(\n",
    "                                f\"Epoch {epoch + 1} not pass the Early Stopping! EarlyStopping counter: {self.counter} / {self.patience}\")\n",
    "                            logger.info(f\"The best val_loss and accuracy / weighted f1 score are still: {self.best[0]}, {self.best[1]}\")\n",
    "                            if self.counter >= self.patience or (epoch + 1) == self.epoch_number:\n",
    "                                self.early_stop = True\n",
    "\n",
    "            num_epochs = config['num_epochs']\n",
    "            warm_up_epochs = config['warmup_epoch']\n",
    "            total_steps = (config['warmup_epoch'] + config['lr_decay_epoch']) * len(train_loader)\n",
    "            warm_up_steps = warm_up_epochs * len(train_loader)\n",
    "            # Set L.F., optimizer\n",
    "            train_criterion = nn.CrossEntropyLoss(label_smoothing=config['label_smoothing'])\n",
    "            val_criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "            optimizer = optim.AdamW([{'params': filter(lambda p: p.requires_grad, model.base_model.parameters()), 'weight_decay': config['weight_decay_backbone'], 'lr': config['lr_backbone']}, {'params': model.head.parameters(), 'weight_decay': config['weight_decay_head'], 'lr': config['lr_head']}])\n",
    "            scheduler = get_cosine_with_warmup_tail(optimizer, num_warmup_steps=warm_up_steps, num_training_steps=total_steps, min_lr_factor=0.1)  # the learning rate will warm-up firstly, then cosine decay to 0.1 of the initial lr\n",
    "\n",
    "\n",
    "            # train func\n",
    "            def train(model, loader, criterion, optimizer, device, epoch, train_dataset):\n",
    "                model.train()  # set model to train mode\n",
    "                running_loss = 0.0\n",
    "                for i, data in enumerate(loader, 0):  # each batch input\n",
    "                    inputs, targets = data\n",
    "                    if i == 0:\n",
    "                        logger.info(f\"First train batch labels: {targets}\")\n",
    "                    inputs, targets = inputs.to(device), targets.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    loss.backward()  # back propagation\n",
    "                    if config['grad_clip']:\n",
    "                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # gradients clip\n",
    "                    optimizer.step()  # update parameter\n",
    "                    running_loss += loss.item() * targets.size(0)\n",
    "                    logger.info(\"In epoch \" + str(epoch + 1) + \", batch: \" + str(i + 1) + \", average loss per image: \" + str(\n",
    "                        loss.item()))\n",
    "\n",
    "                    correct_train = 0\n",
    "                    _, predicted_train = outputs.max(1)  # model predicted class\n",
    "                    correct_train += (predicted_train == targets).sum().item()\n",
    "                    logger.info(\"Accuracy of the network on the train set: \" + str(correct_train / targets.size(0)))\n",
    "\n",
    "                    scheduler.step()  # regularize the learning rate\n",
    "\n",
    "                return running_loss / len(train_dataset)\n",
    "\n",
    "\n",
    "            # validate func\n",
    "            def validate(model, loader, criterion, device, val_dataset):\n",
    "                model.eval()  # set model to validate mode\n",
    "                correct = 0\n",
    "                total = 0\n",
    "                false = []\n",
    "                running_loss = 0.0\n",
    "                y_true = []\n",
    "                y_pred = []\n",
    "                with torch.no_grad():\n",
    "                    for i, data in enumerate(loader, 0):\n",
    "                        inputs, targets = data\n",
    "                        inputs, targets = inputs.to(device), targets.to(device)\n",
    "                        outputs = model(inputs)\n",
    "                        _, predicted = outputs.max(1)  # model predicted class\n",
    "                        correct += (predicted == targets).sum().item()\n",
    "                        total += targets.size(0)\n",
    "                        loss = criterion(outputs, targets)\n",
    "                        running_loss += loss.item() # the sum of val_loss in one batch\n",
    "\n",
    "                        for target in targets:\n",
    "                            y_true.append(target.item())\n",
    "                        for predict in predicted:\n",
    "                            y_pred.append(predict.item())\n",
    "\n",
    "                        for result in range(len(predicted)): # collect wrong samples\n",
    "                            if predicted[result] != targets[result]:\n",
    "                                false.append(i * batch_size + result)\n",
    "\n",
    "                    y_true = np.array(y_true)\n",
    "                    y_pred = np.array(y_pred)\n",
    "\n",
    "                return correct / total, false, running_loss / total, f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "\n",
    "            # train and validate\n",
    "            early_stopping = EarlyStopping(patience=10, mode=early_stop_mode, fold=fold, epoch_number = num_epochs, name = main_structure, hyper_index = set_num)\n",
    "            wrong_number = []\n",
    "\n",
    "            training_loss_list = []\n",
    "            validating_loss_list = []\n",
    "            for epoch in range(num_epochs):\n",
    "                logger.info(f\"The learning rate of backbone is: {optimizer.param_groups[0]['lr']}, of head is {optimizer.param_groups[1]['lr']}\")\n",
    "                train_loss = train(model, train_loader, train_criterion, optimizer, device, epoch, train_dataset[fold])\n",
    "                accuracy, wrong_predicted, val_loss, weighted_f1 = validate(model, val_loader, val_criterion, device, val_dataset[fold])\n",
    "                wrong_number.append(wrong_predicted)\n",
    "                logger.info(\"====================\" + str(epoch + 1) + \"====================\")\n",
    "                logger.info(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "                logger.info(f'Average train loss per image: {train_loss:.7f}')\n",
    "                logger.info(f'Average validate loss per image: {val_loss:.7f}')\n",
    "                logger.info(f'Validate accuracy: {accuracy:.4f}')\n",
    "                logger.info(\"====================\" + str(epoch + 1) + \"====================\")\n",
    "\n",
    "                training_loss_list.append(train_loss)\n",
    "                validating_loss_list.append(val_loss)\n",
    "                early_stopping(val_loss, weighted_f1, epoch)\n",
    "\n",
    "                if early_stopping.early_stop:\n",
    "                    logger.info(\" ðŸ”¥ Early stopping, Stop Training\")\n",
    "                    logger.info(f\"select the epoch: {epoch - early_stopping.counter + 1}\")\n",
    "                    for wrong_result in wrong_number[epoch - early_stopping.counter]:\n",
    "                        logger.info(\"The number \" + str(wrong_result) + \" is wrong!\")\n",
    "                    break\n",
    "\n",
    "                if epoch == num_epochs - 1:\n",
    "                    logger.info(\"train until the last epoch!\")\n",
    "                    for wrong_result in wrong_predicted:\n",
    "                        logger.info(\"The number \" + str(wrong_result) + \" is wrong!\")\n",
    "\n",
    "            plot_loss_curves(training_loss_list, validating_loss_list, fold_number = fold, hyper_setnum=set_num, model_type = main_structure)\n",
    "\n",
    "        inspect_model_and_optimizer(model, optimizer, logger)\n",
    "\n",
    "        logger.info(\"#####################################################################\")\n",
    "        logger.info(f'Using model: {main_structure}')\n",
    "        logger.info(\"#####################################################################\")\n",
    "\n",
    "        model_accuracy = []\n",
    "        model_recall = []\n",
    "        model_precision = []\n",
    "        model_specificity = []\n",
    "        model_auc_roc_macro = []\n",
    "        model_auc_roc_micro = []\n",
    "        model_auc_roc_weighted = []\n",
    "        model_f1_macro = []\n",
    "        model_f1_micro = []\n",
    "        model_f1_weighted = []\n",
    "\n",
    "\n",
    "        for fold in range(fold_num):\n",
    "            model.load_state_dict(torch.load(main_structure + \"_best_model_parameter_\" + str(set_num) + \"_\" + str(fold) + \".pth\"))\n",
    "            model.eval()\n",
    "            y_true = []\n",
    "            y_pred = []\n",
    "            y_prob = []\n",
    "\n",
    "            for data in range(len(val_dataset[fold])):\n",
    "                y_true.append(val_dataset[fold][data][1])\n",
    "\n",
    "                inputs = val_dataset[fold][data][0]\n",
    "                inputs = inputs.to(device)\n",
    "                input_tensor = inputs.unsqueeze(0).to(device)\n",
    "                outputs = model(input_tensor)\n",
    "                predicted_class = outputs.argmax(dim=1).item()\n",
    "                y_pred.append(predicted_class)\n",
    "\n",
    "                prob = torch.softmax(outputs, dim=1)[:, 1].item()\n",
    "                y_prob.append(prob)\n",
    "\n",
    "            y_true = np.array(y_true)\n",
    "            y_pred = np.array(y_pred)\n",
    "            y_prob = np.array(y_prob)\n",
    "\n",
    "            fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "            plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "            plt.xlim([0.0, 1.0])\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title('Receiver Operating Characteristic')\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.show()\n",
    "\n",
    "            recall = recall_score(y_true, y_pred)\n",
    "            precision = precision_score(y_true, y_pred)\n",
    "            auc_roc_macro = roc_auc_score(y_true, y_prob)\n",
    "            auc_roc_micro = roc_auc_score(y_true, y_prob)\n",
    "            auc_roc_weighted = roc_auc_score(y_true, y_prob)\n",
    "            f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "            f1_micro = f1_score(y_true, y_pred, average='micro')\n",
    "            f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "            accuracy = 0.0\n",
    "            for i in range(len(y_pred)):\n",
    "                if y_pred[i] == y_true[i]:\n",
    "                    accuracy += 1.0\n",
    "            tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "            specificity = tn / (tn + fp)\n",
    "            model_accuracy.append(accuracy/len(y_pred))\n",
    "            model_recall.append(recall)\n",
    "            model_precision.append(precision)\n",
    "            model_specificity.append(specificity)\n",
    "            model_auc_roc_macro.append(auc_roc_macro)\n",
    "            model_auc_roc_micro.append(auc_roc_micro)\n",
    "            model_auc_roc_weighted.append(auc_roc_weighted)\n",
    "            model_f1_macro.append(f1_macro)\n",
    "            model_f1_micro.append(f1_micro)\n",
    "            model_f1_weighted.append(f1_weighted)\n",
    "\n",
    "            logger.info(f\"Accuracy: {accuracy/len(y_pred):.4f}\")\n",
    "            logger.info(f\"Recall: {recall:.4f}\")\n",
    "            logger.info(f\"Precision: {precision:.4f}\")\n",
    "            logger.info(f\"Specificity: {specificity:.4f}\")\n",
    "            logger.info(f\"AUC-ROC Macro: {auc_roc_macro:.4f}\")\n",
    "            logger.info(f\"AUC-ROC Micro: {auc_roc_micro:.4f}\")\n",
    "            logger.info(f\"AUC-ROC Weighted: {auc_roc_weighted:.4f}\")\n",
    "            logger.info(f\"F1 Macro: {f1_macro:.4f}\")\n",
    "            logger.info(f\"F1 Micro: {f1_micro:.4f}\")\n",
    "            logger.info(f\"F1 Weighted: {f1_weighted:.4f}\")\n",
    "\n",
    "        logger.info(f\"The mean and std of accuracy are: {np.array(model_accuracy).mean()}, and {np.array(model_accuracy).std()}\")\n",
    "        logger.info(f\"The mean and std of recall are: {np.array(model_recall).mean()}, and {np.array(model_recall).std()}\")\n",
    "        logger.info(f\"The mean and std of precision are: {np.array(model_precision).mean()}, and {np.array(model_precision).std()}\")\n",
    "        logger.info(f\"The mean and std of specificity are: {np.array(model_specificity).mean()}, and {np.array(model_specificity).std()}\")\n",
    "        logger.info(f\"The mean and std of auc_roc_macro are: {np.array(model_auc_roc_macro).mean()}, and {np.array(model_auc_roc_macro).std()}\")\n",
    "        logger.info(f\"The mean and std of auc_roc_micro are: {np.array(model_auc_roc_micro).mean()}, and {np.array(model_auc_roc_micro).std()}\")\n",
    "        logger.info(f\"The mean and std of auc_roc_weighted are: {np.array(model_auc_roc_weighted).mean()}, and {np.array(model_auc_roc_weighted).std()}\")\n",
    "        logger.info(f\"The mean and std of f1_macro are: {np.array(model_f1_macro).mean()}, and {np.array(model_f1_macro).std()}\")\n",
    "        logger.info(f\"The mean and std of f1_micro are: {np.array(model_f1_micro).mean()}, and {np.array(model_f1_micro).std()}\")\n",
    "        logger.info(f\"The mean and std of f1_weighted are: {np.array(model_f1_weighted).mean()}, and {np.array(model_f1_weighted).std()}\")\n",
    "\n",
    "        gird_search_result.append({'model name': main_structure,\n",
    "                                   'hyperparams': hyper_params,\n",
    "                                   'accuracy mean':np.array(model_accuracy).mean(),\n",
    "                                   'accuracy std': np.array(model_accuracy).std(),\n",
    "                                   'recall mean': np.array(model_recall).mean(),\n",
    "                                   'recall std': np.array(model_recall).std(),\n",
    "                                   'precision mean': np.array(model_precision).mean(),\n",
    "                                   'precision std': np.array(model_precision).std(),\n",
    "                                   \"specificity mean\": np.array(model_specificity).mean(),\n",
    "                                   \"specificity std\": np.array(model_specificity).std(),\n",
    "                                   'auc_roc_macro mean': np.array(model_auc_roc_macro).mean(),\n",
    "                                   'auc_roc_macro std': np.array(model_auc_roc_macro).std(),\n",
    "                                   'auc_roc_micro mean': np.array(model_auc_roc_micro).mean(),\n",
    "                                   'auc_roc_micro std': np.array(model_auc_roc_micro).std(),\n",
    "                                   'auc_roc_weighted mean': np.array(model_auc_roc_weighted).mean(),\n",
    "                                   'auc_roc_weighted std': np.array(model_auc_roc_weighted).std(),\n",
    "                                   'f1_macro mean': np.array(model_f1_macro).mean(),\n",
    "                                   'f1_macro std': np.array(model_f1_macro).std(),\n",
    "                                   'f1_micro mean': np.array(model_f1_micro).mean(),\n",
    "                                   'f1_micro std': np.array(model_f1_micro).std(),\n",
    "                                   'f1_weighted mean': np.array(model_f1_weighted).mean(),\n",
    "                                   'f1_weighted std': np.array(model_f1_weighted).std()})\n",
    "\n",
    "else:\n",
    "    if finetune:\n",
    "        param_grid = {\n",
    "        'lr_backbone': [0.00002, 0.0001],\n",
    "        'lr_head': [0.0002, 0.001],\n",
    "        'weight_decay_backbone': [0.01, 0.001],\n",
    "        'weight_decay_head': [0.000],\n",
    "        'dropout_p': [0.3],\n",
    "        'warmup_epoch': [5],\n",
    "        'lr_decay_epoch': [40],\n",
    "        'unfrozen_blocks': [[0,1,2,3,4,5,6,7,8,9,10,11]],\n",
    "        'grad_clip': [False],\n",
    "        'label_smoothing': [0.0]\n",
    "        }\n",
    "    else:\n",
    "        param_grid = {\n",
    "        'lr_backbone': [0.00002],\n",
    "        'lr_head': [0.0002, 0.001],\n",
    "        'weight_decay_backbone': [0.01],\n",
    "        'weight_decay_head': [0.000, 0.001],\n",
    "        'dropout_p': [0.3, 0.0],\n",
    "        'warmup_epoch': [5],\n",
    "        'lr_decay_epoch': [40],\n",
    "        'unfrozen_blocks': [[0,1,2,3,4,5,6,7,8,9,10,11]],\n",
    "        'grad_clip': [False],\n",
    "        'label_smoothing': [0.0]\n",
    "        }\n",
    "    grid = list(ParameterGrid(param_grid)) # generate all the hyper-parameter combination\n",
    "    gird_search_result = [] # store the cross-validation performance of each hyper-parameter set\n",
    "    for set_num, hyper_params in enumerate(grid):\n",
    "\n",
    "        config = {\n",
    "        'lr_backbone': hyper_params['lr_backbone'],\n",
    "        'lr_head': hyper_params['lr_head'],\n",
    "        'weight_decay_backbone': hyper_params['weight_decay_backbone'],\n",
    "        'weight_decay_head': hyper_params['weight_decay_head'],\n",
    "        'dropout_p': hyper_params['dropout_p'],\n",
    "        'num_epochs': 60,\n",
    "        'warmup_epoch': hyper_params['warmup_epoch'],\n",
    "        'lr_decay_epoch': hyper_params['lr_decay_epoch'],\n",
    "        'unfrozen_blocks': hyper_params['unfrozen_blocks'],\n",
    "        'grad_clip': hyper_params['grad_clip'],\n",
    "        'label_smoothing': hyper_params['label_smoothing']\n",
    "        } # configure all the hyper-parameters, including not for grid search\n",
    "\n",
    "        logger.info(f\"Running config {set_num + 1}/{len(grid)}: {config}\")\n",
    "\n",
    "        for model_name in baseline_model:\n",
    "            logger.info(\"#####################################################################\")\n",
    "            logger.info(f'Using model: {model_name}')\n",
    "            logger.info(\"#####################################################################\")\n",
    "\n",
    "            for fold in range(fold_num):\n",
    "                logger.info('###############################################')\n",
    "                logger.info(f'This is the fold: {fold}')\n",
    "                logger.info('###############################################')\n",
    "\n",
    "                g = torch.Generator()\n",
    "                g.manual_seed(42 + fold)\n",
    "\n",
    "                # Load the train, validate, and test dataset, ensure the sequences of training samples in the same fold of different hyperparameter sets to keep same.\n",
    "                train_loader = DataLoader(train_dataset[fold], batch_size=batch_size, shuffle=True, generator=g, pin_memory=True)\n",
    "                val_loader = DataLoader(val_dataset[fold], batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "                test_loader = DataLoader(test_dataset[fold], batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "\n",
    "\n",
    "                # Set gpu/cpu\n",
    "                logger.info(f\"Use device: {device}\")\n",
    "\n",
    "                model = torch.hub.load('pytorch/vision', model_name, pretrained=True)\n",
    "\n",
    "                model, num_features = replace_classifier(model)\n",
    "                model = model.to(device)\n",
    "\n",
    "                class ModifiedCNN(nn.Module):\n",
    "                    def __init__(self, base_model, in_features):\n",
    "                        super(ModifiedCNN, self).__init__()\n",
    "                        self.base_model = base_model\n",
    "                        self.head = nn.Sequential(nn.Dropout(config['dropout_p']),\n",
    "                                                  nn.Linear(in_features, 2))  # modify the head from Identify to 2-class classification (Linear Layer) and add drop out (included in grid search)\n",
    "\n",
    "                    def forward(self, x):\n",
    "                        # the features from ViT backbone (batch size, 768 (dim of class token))\n",
    "                        features = self.base_model(x)\n",
    "                        # pass the classification head\n",
    "                        return self.head(features)\n",
    "\n",
    "                model = ModifiedCNN(model, num_features).to(device)\n",
    "\n",
    "                if finetune:\n",
    "                    for param in model.parameters():\n",
    "                        param.requires_grad = True\n",
    "                else:\n",
    "                    for param in model.parameters():\n",
    "                        param.requires_grad = False\n",
    "                    for param in model.head.parameters(): # un froze the classification head\n",
    "                        param.requires_grad = True\n",
    "                    model.base_model.eval()\n",
    "\n",
    "                class EarlyStopping:\n",
    "                    def __init__(self, patience=5, mode='loss', min_delta=0.0, fold=0, epoch_number = 10, name = None, hyper_index = 0):\n",
    "                        self.patience = patience\n",
    "                        self.mode = mode\n",
    "                        self.fold = fold\n",
    "                        self.min_delta = min_delta\n",
    "                        self.counter = 0\n",
    "                        self.epoch_number = epoch_number\n",
    "                        self.name = name\n",
    "                        self.hyper_index = hyper_index\n",
    "                        self.best = None\n",
    "                        self.early_stop = False\n",
    "\n",
    "                    def __call__(self, val_loss, accuracy, epoch):\n",
    "                        logger.info(\"the mode of early stopping is \" + self.mode)\n",
    "                        if self.mode == 'loss':\n",
    "                            if self.best is None:\n",
    "                                logger.info(f\"This is the first epoch {epoch + 1}!\")\n",
    "                                self.best = val_loss\n",
    "                                torch.save(model.state_dict(), self.name + \"_best_model_parameter_\" + str(self.hyper_index) + \"_\" + str(self.fold) + \".pth\")\n",
    "                                logger.info(f\"The best val_loss is: {self.best}\")\n",
    "                            elif val_loss < self.best - self.min_delta:\n",
    "                                logger.info(f\"Epoch {epoch + 1} Early Stop Check Pass!\")\n",
    "                                self.best = val_loss\n",
    "                                self.counter = 0\n",
    "                                torch.save(model.state_dict(), self.name + \"_best_model_parameter_\" + str(self.hyper_index) + \"_\" + str(self.fold) + \".pth\")\n",
    "                                logger.info(f\"The best val_loss is: {self.best}\")\n",
    "                            else:\n",
    "                                self.counter += 1\n",
    "                                logger.info(\n",
    "                                    f\"Epoch {epoch + 1} not pass the Early Stopping! EarlyStopping counter: {self.counter} / {self.patience}\")\n",
    "                                logger.info(f\"The best val_loss is still: {self.best}\")\n",
    "                                if self.counter >= self.patience or (epoch + 1) == self.epoch_number:\n",
    "                                    self.early_stop = True\n",
    "                        elif self.mode == 'accuracy':\n",
    "                            if self.best is None:\n",
    "                                logger.info(f\"This is the first epoch {epoch + 1}!\")\n",
    "                                self.best = [val_loss, accuracy]\n",
    "                                torch.save(model.state_dict(), self.name + \"_best_model_parameter_\" + str(self.hyper_index) + \"_\" + str(self.fold) + \".pth\")\n",
    "                                logger.info(f\"The best accuracy / weighted f1 score is: {self.best[1]}\")\n",
    "                            elif accuracy > self.best[1]:\n",
    "                                logger.info(f\"Epoch {epoch + 1} Early Stop Check Pass!\")\n",
    "                                self.best = [val_loss, accuracy]\n",
    "                                self.counter = 0\n",
    "                                torch.save(model.state_dict(), self.name + \"_best_model_parameter_\" + str(self.hyper_index) + \"_\" + str(self.fold) + \".pth\")\n",
    "                                logger.info(f\"The best accuracy / weighted f1 score is: {self.best[1]}\")\n",
    "                            elif accuracy == self.best[1] and val_loss < self.best[0]:\n",
    "                                logger.info(f\"Epoch {epoch + 1} Early Stop Check Pass! val_loss is smaller although the accuracy / weighted f1 score keeps the same.\")\n",
    "                                self.best = [val_loss, accuracy]\n",
    "                                self.counter = 0\n",
    "                                torch.save(model.state_dict(), self.name + \"_best_model_parameter_\" + str(self.hyper_index) + \"_\" + str(self.fold) + \".pth\")\n",
    "                                logger.info(f\"The best accuracy / weighted f1 score is: {self.best[1]}\")\n",
    "                            else:\n",
    "                                self.counter += 1\n",
    "                                logger.info(\n",
    "                                    f\"Epoch {epoch + 1} not pass the Early Stopping! EarlyStopping counter: {self.counter} / {self.patience}\")\n",
    "                                logger.info(f\"The best accuracy / weighted f1 score is still: {self.best[1]}\")\n",
    "                                if self.counter >= self.patience or (epoch + 1) == self.epoch_number:\n",
    "                                    self.early_stop = True\n",
    "                        elif self.mode == 'loss and accuracy':\n",
    "                            if self.best is None:\n",
    "                                logger.info(f\"This is the first epoch {epoch + 1}!\")\n",
    "                                self.best = [val_loss, accuracy]\n",
    "                                torch.save(model.state_dict(), self.name + \"_best_model_parameter_\" + str(self.hyper_index) + \"_\" + str(self.fold) + \".pth\")\n",
    "                                logger.info(f\"The best val_loss and accuracy / weighted f1 score are: {self.best[0]}, {self.best[1]}\")\n",
    "                            elif val_loss < self.best[0] - self.min_delta and accuracy > self.best[1]:\n",
    "                                logger.info(f\"Epoch {epoch + 1} Early Stop Check Pass!\")\n",
    "                                self.best = [val_loss, accuracy]\n",
    "                                self.counter = 0\n",
    "                                torch.save(model.state_dict(), self.name + \"_best_model_parameter_\" + str(self.hyper_index) + \"_\" + str(self.fold) + \".pth\")\n",
    "                                logger.info(f\"The best val_loss and accuracy / weighted f1 score are: {self.best[0]}, {self.best[1]}\")\n",
    "                            else:\n",
    "                                self.counter += 1\n",
    "                                logger.info(\n",
    "                                    f\"Epoch {epoch + 1} not pass the Early Stopping! EarlyStopping counter: {self.counter} / {self.patience}\")\n",
    "                                logger.info(f\"The best val_loss and accuracy / weighted f1 score are still: {self.best[0]}, {self.best[1]}\")\n",
    "                                if self.counter >= self.patience or (epoch + 1) == self.epoch_number:\n",
    "                                    self.early_stop = True\n",
    "                        elif self.mode == 'loss or accuracy':\n",
    "                            if self.best is None:\n",
    "                                logger.info(f\"This is the first epoch {epoch + 1}!\")\n",
    "                                self.best = [val_loss, accuracy]\n",
    "                                torch.save(model.state_dict(), self.name + \"_best_model_parameter_\" + str(self.hyper_index) + \"_\" + str(self.fold) + \".pth\")\n",
    "                                logger.info(f\"The best val_loss and accuracy / weighted f1 score are: {self.best[0]}, {self.best[1]}\")\n",
    "                            elif val_loss < self.best[0] - self.min_delta or accuracy > self.best[1]:\n",
    "                                logger.info(f\"Epoch {epoch + 1} Early Stop Check Pass!\")\n",
    "                                self.best = [val_loss, accuracy]\n",
    "                                self.counter = 0\n",
    "                                torch.save(model.state_dict(), self.name + \"_best_model_parameter_\" + str(self.hyper_index) + \"_\" + str(self.fold) + \".pth\")\n",
    "                                logger.info(f\"The best val_loss and accuracy / weighted f1 score are: {self.best[0]}, {self.best[1]}\")\n",
    "                            else:\n",
    "                                self.counter += 1\n",
    "                                logger.info(\n",
    "                                    f\"Epoch {epoch + 1} not pass the Early Stopping! EarlyStopping counter: {self.counter} / {self.patience}\")\n",
    "                                logger.info(f\"The best val_loss and accuracy / weighted f1 score are still: {self.best[0]}, {self.best[1]}\")\n",
    "                                if self.counter >= self.patience or (epoch + 1) == self.epoch_number:\n",
    "                                    self.early_stop = True\n",
    "\n",
    "                num_epochs = config['num_epochs']\n",
    "                warm_up_epochs = config['warmup_epoch']\n",
    "                total_steps = (config['warmup_epoch'] + config['lr_decay_epoch']) * len(train_loader)\n",
    "                warm_up_steps = warm_up_epochs * len(train_loader)\n",
    "                # Set L.F., optimizer\n",
    "                train_criterion = nn.CrossEntropyLoss(label_smoothing=config['label_smoothing'])\n",
    "                val_criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "                optimizer = optim.AdamW([{'params': filter(lambda p: p.requires_grad, model.base_model.parameters()), 'weight_decay': config['weight_decay_backbone'], 'lr': config['lr_backbone']}, {'params': model.head.parameters(), 'weight_decay': config['weight_decay_head'], 'lr': config['lr_head']}])\n",
    "                scheduler = get_cosine_with_warmup_tail(optimizer, num_warmup_steps=warm_up_steps, num_training_steps=total_steps, min_lr_factor=0.1)  # the learning rate will warm-up firstly, then cosine decay to 0.1 of the initial lr\n",
    "\n",
    "\n",
    "                # train func\n",
    "                def train(model, loader, criterion, optimizer, device, epoch, train_dataset):\n",
    "                    model.train()  # set model to train mode\n",
    "                    if not finetune:\n",
    "                        model.base_model.eval()\n",
    "                    running_loss = 0.0\n",
    "                    for i, data in enumerate(loader, 0):  # each batch input\n",
    "                        inputs, targets = data\n",
    "                        if i == 0:\n",
    "                            logger.info(f\"First train batch labels: {targets}\")\n",
    "                        inputs, targets = inputs.to(device), targets.to(device)\n",
    "                        optimizer.zero_grad()\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, targets)\n",
    "                        loss.backward()  # back propagation\n",
    "                        if config['grad_clip']:\n",
    "                            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # gradients clip\n",
    "                        optimizer.step()  # update parameter\n",
    "                        running_loss += loss.item() * targets.size(0)\n",
    "                        logger.info(\"In epoch \" + str(epoch + 1) + \", batch: \" + str(i + 1) + \", average loss per image: \" + str(\n",
    "                            loss.item()))\n",
    "\n",
    "                        correct_train = 0\n",
    "                        _, predicted_train = outputs.max(1)  # model predicted class\n",
    "                        correct_train += (predicted_train == targets).sum().item()\n",
    "                        logger.info(\"Accuracy of the network on the train set: \" + str(correct_train / targets.size(0)))\n",
    "\n",
    "                        scheduler.step()  # regularize the learning rate\n",
    "\n",
    "                    return running_loss / len(train_dataset)\n",
    "\n",
    "\n",
    "                # validate func\n",
    "                def validate(model, loader, criterion, device, val_dataset):\n",
    "                    model.eval()  # set model to validate mode\n",
    "                    correct = 0\n",
    "                    total = 0\n",
    "                    false = []\n",
    "                    running_loss = 0.0\n",
    "                    y_true = []\n",
    "                    y_pred = []\n",
    "                    with torch.no_grad():\n",
    "                        for i, data in enumerate(loader, 0):\n",
    "                            inputs, targets = data\n",
    "                            inputs, targets = inputs.to(device), targets.to(device)\n",
    "                            outputs = model(inputs)\n",
    "                            _, predicted = outputs.max(1)  # model predicted class\n",
    "                            correct += (predicted == targets).sum().item()\n",
    "                            total += targets.size(0)\n",
    "                            loss = criterion(outputs, targets)\n",
    "                            running_loss += loss.item() # the sum of val_loss in one batch\n",
    "\n",
    "                            for target in targets:\n",
    "                                y_true.append(target.item())\n",
    "                            for predict in predicted:\n",
    "                                y_pred.append(predict.item())\n",
    "\n",
    "                            for result in range(len(predicted)): # collect wrong samples\n",
    "                                if predicted[result] != targets[result]:\n",
    "                                    false.append(i * batch_size + result)\n",
    "\n",
    "                        y_true = np.array(y_true)\n",
    "                        y_pred = np.array(y_pred)\n",
    "\n",
    "                    return correct / total, false, running_loss / total, f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "\n",
    "                # train and validate\n",
    "                early_stopping = EarlyStopping(patience=10, mode=early_stop_mode, fold=fold, epoch_number = num_epochs, name = model_name, hyper_index = set_num)\n",
    "                wrong_number = []\n",
    "\n",
    "                training_loss_list = []\n",
    "                validating_loss_list = []\n",
    "                for epoch in range(num_epochs):\n",
    "                    logger.info(f\"The learning rate of backbone is: {optimizer.param_groups[0]['lr']}, of head is {optimizer.param_groups[1]['lr']}\")\n",
    "                    train_loss = train(model, train_loader, train_criterion, optimizer, device, epoch, train_dataset[fold])\n",
    "                    accuracy, wrong_predicted, val_loss, weighted_f1 = validate(model, val_loader, val_criterion, device, val_dataset[fold])\n",
    "                    wrong_number.append(wrong_predicted)\n",
    "                    logger.info(\"====================\" + str(epoch + 1) + \"====================\")\n",
    "                    logger.info(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "                    logger.info(f'Average train loss per image: {train_loss:.7f}')\n",
    "                    logger.info(f'Average validate loss per image: {val_loss:.7f}')\n",
    "                    logger.info(f'Validate accuracy: {accuracy:.4f}')\n",
    "                    logger.info(\"====================\" + str(epoch + 1) + \"====================\")\n",
    "\n",
    "                    training_loss_list.append(train_loss)\n",
    "                    validating_loss_list.append(val_loss)\n",
    "\n",
    "                    early_stopping(val_loss, weighted_f1, epoch)\n",
    "\n",
    "                    if early_stopping.early_stop:\n",
    "                        logger.info(\" ðŸ”¥ Early stopping, Stop Training\")\n",
    "                        logger.info(f\"select the epoch: {epoch - early_stopping.counter + 1}\")\n",
    "                        for wrong_result in wrong_number[epoch - early_stopping.counter]:\n",
    "                            logger.info(\"The number \" + str(wrong_result) + \" is wrong!\")\n",
    "                        break\n",
    "\n",
    "                    if epoch == num_epochs - 1:\n",
    "                        logger.info(\"train until the last epoch!\")\n",
    "                        for wrong_result in wrong_predicted:\n",
    "                            logger.info(\"The number \" + str(wrong_result) + \" is wrong!\")\n",
    "\n",
    "                plot_loss_curves(training_loss_list, validating_loss_list, fold_number = fold, hyper_setnum=set_num, model_type = model_name)\n",
    "\n",
    "            inspect_model_and_optimizer(model, optimizer, logger)\n",
    "\n",
    "        for model_name in baseline_model:\n",
    "            logger.info(\"#####################################################################\")\n",
    "            logger.info(f'Using model: {model_name}')\n",
    "            logger.info(\"#####################################################################\")\n",
    "            model_accuracy = []\n",
    "            model_recall = []\n",
    "            model_precision = []\n",
    "            model_specificity = []\n",
    "            model_auc_roc_macro = []\n",
    "            model_auc_roc_micro = []\n",
    "            model_auc_roc_weighted = []\n",
    "            model_f1_macro = []\n",
    "            model_f1_micro = []\n",
    "            model_f1_weighted = []\n",
    "\n",
    "            model = torch.hub.load('pytorch/vision', model_name, pretrained=True)\n",
    "\n",
    "            model, num_features = replace_classifier(model)\n",
    "            model = model.to(device)\n",
    "\n",
    "            class ModifiedCnnVal(nn.Module):\n",
    "                def __init__(self, base_model, in_features):\n",
    "                    super(ModifiedCnnVal, self).__init__()\n",
    "                    self.base_model = base_model\n",
    "                    self.head = nn.Sequential(nn.Dropout(config['dropout_p']),\n",
    "                                              nn.Linear(in_features, 2))  # modify the head from Identify to 2-class classification (Linear Layer) and add drop out (included in grid search)\n",
    "\n",
    "                def forward(self, x):\n",
    "                    # the features from ViT backbone (batch size, 768 (dim of class token))\n",
    "                    features = self.base_model(x)\n",
    "                    # pass the classification head\n",
    "                    return self.head(features)\n",
    "\n",
    "            model = ModifiedCnnVal(model, num_features).to(device)\n",
    "\n",
    "\n",
    "            for fold in range(fold_num):\n",
    "                model.load_state_dict(torch.load(model_name + \"_best_model_parameter_\" + str(set_num) + \"_\" + str(fold) + \".pth\"))\n",
    "                model.eval()\n",
    "                y_true = []\n",
    "                y_pred = []\n",
    "                y_prob = []\n",
    "\n",
    "                for data in range(len(val_dataset[fold])):\n",
    "                    y_true.append(val_dataset[fold][data][1])\n",
    "\n",
    "                    inputs = val_dataset[fold][data][0]\n",
    "                    inputs = inputs.to(device)\n",
    "                    input_tensor = inputs.unsqueeze(0).to(device)\n",
    "                    outputs = model(input_tensor)\n",
    "                    predicted_class = outputs.argmax(dim=1).item()\n",
    "                    y_pred.append(predicted_class)\n",
    "\n",
    "                    prob = torch.softmax(outputs, dim=1)[:, 1].item()\n",
    "                    y_prob.append(prob)\n",
    "\n",
    "                y_true = np.array(y_true)\n",
    "                y_pred = np.array(y_pred)\n",
    "                y_prob = np.array(y_prob)\n",
    "\n",
    "                fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "\n",
    "                plt.figure()\n",
    "                plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "                plt.xlim([0.0, 1.0])\n",
    "                plt.ylim([0.0, 1.05])\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title('Receiver Operating Characteristic')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.show()\n",
    "\n",
    "                recall = recall_score(y_true, y_pred)\n",
    "                precision = precision_score(y_true, y_pred)\n",
    "                auc_roc_macro = roc_auc_score(y_true, y_prob)\n",
    "                auc_roc_micro = roc_auc_score(y_true, y_prob)\n",
    "                auc_roc_weighted = roc_auc_score(y_true, y_prob)\n",
    "                f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "                f1_micro = f1_score(y_true, y_pred, average='micro')\n",
    "                f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "                accuracy = 0.0\n",
    "                for i in range(len(y_pred)):\n",
    "                    if y_pred[i] == y_true[i]:\n",
    "                        accuracy += 1.0\n",
    "                tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "                specificity = tn / (tn + fp)\n",
    "                model_accuracy.append(accuracy/len(y_pred))\n",
    "                model_recall.append(recall)\n",
    "                model_precision.append(precision)\n",
    "                model_specificity.append(specificity)\n",
    "                model_auc_roc_macro.append(auc_roc_macro)\n",
    "                model_auc_roc_micro.append(auc_roc_micro)\n",
    "                model_auc_roc_weighted.append(auc_roc_weighted)\n",
    "                model_f1_macro.append(f1_macro)\n",
    "                model_f1_micro.append(f1_micro)\n",
    "                model_f1_weighted.append(f1_weighted)\n",
    "\n",
    "                logger.info(f\"Accuracy: {accuracy/len(y_pred):.4f}\")\n",
    "                logger.info(f\"Recall: {recall:.4f}\")\n",
    "                logger.info(f\"Precision: {precision:.4f}\")\n",
    "                logger.info(f\"Specificity: {specificity:.4f}\")\n",
    "                logger.info(f\"AUC-ROC Macro: {auc_roc_macro:.4f}\")\n",
    "                logger.info(f\"AUC-ROC Micro: {auc_roc_micro:.4f}\")\n",
    "                logger.info(f\"AUC-ROC Weighted: {auc_roc_weighted:.4f}\")\n",
    "                logger.info(f\"F1 Macro: {f1_macro:.4f}\")\n",
    "                logger.info(f\"F1 Micro: {f1_micro:.4f}\")\n",
    "                logger.info(f\"F1 Weighted: {f1_weighted:.4f}\")\n",
    "\n",
    "            logger.info(f\"The mean and std of accuracy are: {np.array(model_accuracy).mean()}, and {np.array(model_accuracy).std()}\")\n",
    "            logger.info(f\"The mean and std of recall are: {np.array(model_recall).mean()}, and {np.array(model_recall).std()}\")\n",
    "            logger.info(f\"The mean and std of precision are: {np.array(model_precision).mean()}, and {np.array(model_precision).std()}\")\n",
    "            logger.info(f\"The mean and std of specificity are: {np.array(model_specificity).mean()}, and {np.array(model_specificity).std()}\")\n",
    "            logger.info(f\"The mean and std of auc_roc_macro are: {np.array(model_auc_roc_macro).mean()}, and {np.array(model_auc_roc_macro).std()}\")\n",
    "            logger.info(f\"The mean and std of auc_roc_micro are: {np.array(model_auc_roc_micro).mean()}, and {np.array(model_auc_roc_micro).std()}\")\n",
    "            logger.info(f\"The mean and std of auc_roc_weighted are: {np.array(model_auc_roc_weighted).mean()}, and {np.array(model_auc_roc_weighted).std()}\")\n",
    "            logger.info(f\"The mean and std of f1_macro are: {np.array(model_f1_macro).mean()}, and {np.array(model_f1_macro).std()}\")\n",
    "            logger.info(f\"The mean and std of f1_micro are: {np.array(model_f1_micro).mean()}, and {np.array(model_f1_micro).std()}\")\n",
    "            logger.info(f\"The mean and std of f1_weighted are: {np.array(model_f1_weighted).mean()}, and {np.array(model_f1_weighted).std()}\")\n",
    "\n",
    "            gird_search_result.append({'model name': model_name,\n",
    "                                   'hyperparams': hyper_params,\n",
    "                                   'accuracy mean':np.array(model_accuracy).mean(),\n",
    "                                   'accuracy std': np.array(model_accuracy).std(),\n",
    "                                   'recall mean': np.array(model_recall).mean(),\n",
    "                                   'recall std': np.array(model_recall).std(),\n",
    "                                   'precision mean': np.array(model_precision).mean(),\n",
    "                                   'precision std': np.array(model_precision).std(),\n",
    "                                   \"specificity mean\": np.array(model_specificity).mean(),\n",
    "                                   \"specificity std\": np.array(model_specificity).std(),\n",
    "                                   'auc_roc_macro mean': np.array(model_auc_roc_macro).mean(),\n",
    "                                   'auc_roc_macro std': np.array(model_auc_roc_macro).std(),\n",
    "                                   'auc_roc_micro mean': np.array(model_auc_roc_micro).mean(),\n",
    "                                   'auc_roc_micro std': np.array(model_auc_roc_micro).std(),\n",
    "                                   'auc_roc_weighted mean': np.array(model_auc_roc_weighted).mean(),\n",
    "                                   'auc_roc_weighted std': np.array(model_auc_roc_weighted).std(),\n",
    "                                   'f1_macro mean': np.array(model_f1_macro).mean(),\n",
    "                                   'f1_macro std': np.array(model_f1_macro).std(),\n",
    "                                   'f1_micro mean': np.array(model_f1_micro).mean(),\n",
    "                                   'f1_micro std': np.array(model_f1_micro).std(),\n",
    "                                   'f1_weighted mean': np.array(model_f1_weighted).mean(),\n",
    "                                   'f1_weighted std': np.array(model_f1_weighted).std()})"
   ],
   "id": "703c52df6b15b8f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model print",
   "id": "bb340d324e4ff69e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "logger.info(model)\n",
    "model.eval()"
   ],
   "id": "3ea126ebc766bca6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Print the validation performance of each hyper-parameter set",
   "id": "96f3c1b8ddaa85e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for result in gird_search_result:\n",
    "    for key, value in result.items():\n",
    "        logger.info(f\"{key}: {value}\")"
   ],
   "id": "8c14d1d12b93578e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# After deciding the best 5-fold models (based on the validation set performance and grid search), we use these 5-fold models to predict the test dataset, and calculate the mean and std of the performance metrics like accuracy, recall, precision, etc.",
   "id": "c565b120a1710c18"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "model.eval()\n",
    "\n",
    "if not baseline:\n",
    "\n",
    "    logger.info(\"#####################################################################\")\n",
    "    logger.info(f'Using model: {main_structure}')\n",
    "    logger.info(\"#####################################################################\")\n",
    "\n",
    "    model_accuracy = []\n",
    "    model_recall = []\n",
    "    model_precision = []\n",
    "    model_specificity = []\n",
    "    model_auc_roc_macro = []\n",
    "    model_auc_roc_micro = []\n",
    "    model_auc_roc_weighted = []\n",
    "    model_f1_macro = []\n",
    "    model_f1_micro = []\n",
    "    model_f1_weighted = []\n",
    "\n",
    "    set_num = 0 # users can choose the best hyper-parameter set based on the grid search\n",
    "    dropout = 0.3 # in all-layer finetune, this can use the default value 0.3, but in linear probe, the dropout value of the best hyperparameter set should be entered by users. 0.3 or 0.0\n",
    "    logger.info(\"#####################################################################\")\n",
    "    logger.info(f'Using hyper-parameter set: {set_num}, dropout: {dropout}')\n",
    "    logger.info(\"#####################################################################\")\n",
    "\n",
    "    if main_structure.lower() == 'dino':\n",
    "        model = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16', pretrained=True)\n",
    "        num_features = model.embed_dim\n",
    "    elif main_structure.lower() == 'dinov2':\n",
    "        model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14', pretrained=True)\n",
    "        num_features = model.embed_dim\n",
    "    elif main_structure.lower() == 'dinov3':\n",
    "        model = torch.hub.load(REPO_DINOV3, 'dinov3_vitb16', source='local', weights=WEIGHTS_DINOV3)\n",
    "        num_features = model.embed_dim\n",
    "    elif main_structure.lower() == 'vit':\n",
    "        model = torch.hub.load('pytorch/vision', 'vit_b_16', pretrained=True)\n",
    "        model, num_features = replace_classifier(model)\n",
    "    model = model.to(device)\n",
    "\n",
    "\n",
    "    class ModifiedTestViT(nn.Module):\n",
    "        def __init__(self, base_model, in_features):\n",
    "            super(ModifiedTestViT, self).__init__()\n",
    "            self.base_model = base_model\n",
    "            self.head = nn.Sequential(nn.Dropout(dropout),\n",
    "                                      nn.Linear(in_features, 2))  # modify the head from Identify to 2-class classification (Linear Layer) and add drop out (included in grid search)\n",
    "\n",
    "        def forward(self, x):\n",
    "            # the features from ViT backbone (batch size, 768 (dim of class token))\n",
    "            features = self.base_model(x)\n",
    "            # pass the classification head\n",
    "            return self.head(features)\n",
    "\n",
    "\n",
    "    model = ModifiedTestViT(model, num_features).to(device)\n",
    "\n",
    "    for fold in range(fold_num):\n",
    "        model.load_state_dict(torch.load(main_structure + \"_best_model_parameter_\" + str(set_num) + \"_\" + str(fold) + \".pth\"))\n",
    "        model.eval()\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        y_prob = []\n",
    "\n",
    "        for data in range(len(test_dataset[fold])):\n",
    "            y_true.append(test_dataset[fold][data][1])\n",
    "\n",
    "            inputs = test_dataset[fold][data][0]\n",
    "            inputs = inputs.to(device)\n",
    "            input_tensor = inputs.unsqueeze(0).to(device)\n",
    "            outputs = model(input_tensor)\n",
    "            predicted_class = outputs.argmax(dim=1).item()\n",
    "            y_pred.append(predicted_class)\n",
    "\n",
    "            prob = torch.softmax(outputs, dim=1)[:, 1].item()\n",
    "            y_prob.append(prob)\n",
    "\n",
    "        y_true = np.array(y_true)\n",
    "        y_pred = np.array(y_pred)\n",
    "        y_prob = np.array(y_prob)\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        auc_roc_macro = roc_auc_score(y_true, y_prob)\n",
    "        auc_roc_micro = roc_auc_score(y_true, y_prob)\n",
    "        auc_roc_weighted = roc_auc_score(y_true, y_prob)\n",
    "        f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "        f1_micro = f1_score(y_true, y_pred, average='micro')\n",
    "        f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "        accuracy = 0.0\n",
    "        for i in range(len(y_pred)):\n",
    "            if y_pred[i] == y_true[i]:\n",
    "                accuracy += 1.0\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        specificity = tn / (tn + fp)\n",
    "        model_accuracy.append(accuracy/len(y_pred))\n",
    "        model_recall.append(recall)\n",
    "        model_precision.append(precision)\n",
    "        model_specificity.append(specificity)\n",
    "        model_auc_roc_macro.append(auc_roc_macro)\n",
    "        model_auc_roc_micro.append(auc_roc_micro)\n",
    "        model_auc_roc_weighted.append(auc_roc_weighted)\n",
    "        model_f1_macro.append(f1_macro)\n",
    "        model_f1_micro.append(f1_micro)\n",
    "        model_f1_weighted.append(f1_weighted)\n",
    "\n",
    "        logger.info(f\"Accuracy: {accuracy/len(y_pred):.4f}\")\n",
    "        logger.info(f\"Recall: {recall:.4f}\")\n",
    "        logger.info(f\"Precision: {precision:.4f}\")\n",
    "        logger.info(f\"Specificity: {specificity:.4f}\")\n",
    "        logger.info(f\"AUC-ROC Macro: {auc_roc_macro:.4f}\")\n",
    "        logger.info(f\"AUC-ROC Micro: {auc_roc_micro:.4f}\")\n",
    "        logger.info(f\"AUC-ROC Weighted: {auc_roc_weighted:.4f}\")\n",
    "        logger.info(f\"F1 Macro: {f1_macro:.4f}\")\n",
    "        logger.info(f\"F1 Micro: {f1_micro:.4f}\")\n",
    "        logger.info(f\"F1 Weighted: {f1_weighted:.4f}\")\n",
    "\n",
    "    logger.info(f\"The mean and std of accuracy are: {np.array(model_accuracy).mean()}, and {np.array(model_accuracy).std()}\")\n",
    "    logger.info(f\"The mean and std of recall are: {np.array(model_recall).mean()}, and {np.array(model_recall).std()}\")\n",
    "    logger.info(f\"The mean and std of precision are: {np.array(model_precision).mean()}, and {np.array(model_precision).std()}\")\n",
    "    logger.info(f\"The mean and std of specificity are: {np.array(model_specificity).mean()}, and {np.array(model_specificity).std()}\")\n",
    "    logger.info(f\"The mean and std of auc_roc_macro are: {np.array(model_auc_roc_macro).mean()}, and {np.array(model_auc_roc_macro).std()}\")\n",
    "    logger.info(f\"The mean and std of auc_roc_micro are: {np.array(model_auc_roc_micro).mean()}, and {np.array(model_auc_roc_micro).std()}\")\n",
    "    logger.info(f\"The mean and std of auc_roc_weighted are: {np.array(model_auc_roc_weighted).mean()}, and {np.array(model_auc_roc_weighted).std()}\")\n",
    "    logger.info(f\"The mean and std of f1_macro are: {np.array(model_f1_macro).mean()}, and {np.array(model_f1_macro).std()}\")\n",
    "    logger.info(f\"The mean and std of f1_micro are: {np.array(model_f1_micro).mean()}, and {np.array(model_f1_micro).std()}\")\n",
    "    logger.info(f\"The mean and std of f1_weighted are: {np.array(model_f1_weighted).mean()}, and {np.array(model_f1_weighted).std()}\")\n",
    "else:\n",
    "    set_num = 0 # users can choose the best hyper-parameter set based on the grid search\n",
    "    dropout = 0.3 # in all-layer finetune, this can use the default value 0.3, but in linear probe, the dropout value of the best hyperparameter set should be entered by users. 0.3 or 0.0\n",
    "    logger.info(\"#####################################################################\")\n",
    "    logger.info(f'Using hyper-parameter set: {set_num}, dropout: {dropout}')\n",
    "    logger.info(\"#####################################################################\")\n",
    "\n",
    "    for model_name in baseline_model:\n",
    "        logger.info(\"#####################################################################\")\n",
    "        logger.info(f'Using model: {model_name}')\n",
    "        logger.info(\"#####################################################################\")\n",
    "\n",
    "        model_accuracy = []\n",
    "        model_recall = []\n",
    "        model_precision = []\n",
    "        model_specificity = []\n",
    "        model_auc_roc_macro = []\n",
    "        model_auc_roc_micro = []\n",
    "        model_auc_roc_weighted = []\n",
    "        model_f1_macro = []\n",
    "        model_f1_micro = []\n",
    "        model_f1_weighted = []\n",
    "\n",
    "        model = torch.hub.load('pytorch/vision', model_name, pretrained=True)\n",
    "\n",
    "        model, num_features = replace_classifier(model)\n",
    "        model = model.to(device)\n",
    "\n",
    "        class ModifiedCnnTest(nn.Module):\n",
    "            def __init__(self, base_model, in_features):\n",
    "                super(ModifiedCnnTest, self).__init__()\n",
    "                self.base_model = base_model\n",
    "                self.head = nn.Sequential(nn.Dropout(dropout),\n",
    "                                          nn.Linear(in_features, 2))  # modify the head from Identify to 2-class classification (Linear Layer) and add drop out (included in grid search)\n",
    "\n",
    "            def forward(self, x):\n",
    "                # the features from ViT backbone (batch size, 768 (dim of class token))\n",
    "                features = self.base_model(x)\n",
    "                # pass the classification head\n",
    "                return self.head(features)\n",
    "\n",
    "        model = ModifiedCnnTest(model, num_features).to(device)\n",
    "\n",
    "        for fold in range(fold_num):\n",
    "            model.load_state_dict(torch.load(model_name + \"_best_model_parameter_\" + str(set_num) + \"_\" + str(fold) + \".pth\"))\n",
    "            model.eval()\n",
    "            y_true = []\n",
    "            y_pred = []\n",
    "            y_prob = []\n",
    "\n",
    "            for data in range(len(test_dataset[fold])):\n",
    "                y_true.append(test_dataset[fold][data][1])\n",
    "\n",
    "                inputs = test_dataset[fold][data][0]\n",
    "                inputs = inputs.to(device)\n",
    "                input_tensor = inputs.unsqueeze(0).to(device)\n",
    "                outputs = model(input_tensor)\n",
    "                predicted_class = outputs.argmax(dim=1).item()\n",
    "                y_pred.append(predicted_class)\n",
    "\n",
    "                prob = torch.softmax(outputs, dim=1)[:, 1].item()\n",
    "                y_prob.append(prob)\n",
    "\n",
    "            y_true = np.array(y_true)\n",
    "            y_pred = np.array(y_pred)\n",
    "            y_prob = np.array(y_prob)\n",
    "\n",
    "            fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "            plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "            plt.xlim([0.0, 1.0])\n",
    "            plt.ylim([0.0, 1.05])\n",
    "            plt.xlabel('False Positive Rate')\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.title('Receiver Operating Characteristic')\n",
    "            plt.legend(loc=\"lower right\")\n",
    "            plt.show()\n",
    "\n",
    "            recall = recall_score(y_true, y_pred)\n",
    "            precision = precision_score(y_true, y_pred)\n",
    "            auc_roc_macro = roc_auc_score(y_true, y_prob)\n",
    "            auc_roc_micro = roc_auc_score(y_true, y_prob)\n",
    "            auc_roc_weighted = roc_auc_score(y_true, y_prob)\n",
    "            f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "            f1_micro = f1_score(y_true, y_pred, average='micro')\n",
    "            f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "            accuracy = 0.0\n",
    "            for i in range(len(y_pred)):\n",
    "                if y_pred[i] == y_true[i]:\n",
    "                    accuracy += 1.0\n",
    "            tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "            specificity = tn / (tn + fp)\n",
    "            model_accuracy.append(accuracy/len(y_pred))\n",
    "            model_recall.append(recall)\n",
    "            model_precision.append(precision)\n",
    "            model_specificity.append(specificity)\n",
    "            model_auc_roc_macro.append(auc_roc_macro)\n",
    "            model_auc_roc_micro.append(auc_roc_micro)\n",
    "            model_auc_roc_weighted.append(auc_roc_weighted)\n",
    "            model_f1_macro.append(f1_macro)\n",
    "            model_f1_micro.append(f1_micro)\n",
    "            model_f1_weighted.append(f1_weighted)\n",
    "\n",
    "            logger.info(f\"Accuracy: {accuracy/len(y_pred):.4f}\")\n",
    "            logger.info(f\"Recall: {recall:.4f}\")\n",
    "            logger.info(f\"Precision: {precision:.4f}\")\n",
    "            logger.info(f\"Specificity: {specificity:.4f}\")\n",
    "            logger.info(f\"AUC-ROC Macro: {auc_roc_macro:.4f}\")\n",
    "            logger.info(f\"AUC-ROC Micro: {auc_roc_micro:.4f}\")\n",
    "            logger.info(f\"AUC-ROC Weighted: {auc_roc_weighted:.4f}\")\n",
    "            logger.info(f\"F1 Macro: {f1_macro:.4f}\")\n",
    "            logger.info(f\"F1 Micro: {f1_micro:.4f}\")\n",
    "            logger.info(f\"F1 Weighted: {f1_weighted:.4f}\")\n",
    "\n",
    "        logger.info(f\"The mean and std of accuracy are: {np.array(model_accuracy).mean()}, and {np.array(model_accuracy).std()}\")\n",
    "        logger.info(f\"The mean and std of recall are: {np.array(model_recall).mean()}, and {np.array(model_recall).std()}\")\n",
    "        logger.info(f\"The mean and std of precision are: {np.array(model_precision).mean()}, and {np.array(model_precision).std()}\")\n",
    "        logger.info(f\"The mean and std of specificity are: {np.array(model_specificity).mean()}, and {np.array(model_specificity).std()}\")\n",
    "        logger.info(f\"The mean and std of auc_roc_macro are: {np.array(model_auc_roc_macro).mean()}, and {np.array(model_auc_roc_macro).std()}\")\n",
    "        logger.info(f\"The mean and std of auc_roc_micro are: {np.array(model_auc_roc_micro).mean()}, and {np.array(model_auc_roc_micro).std()}\")\n",
    "        logger.info(f\"The mean and std of auc_roc_weighted are: {np.array(model_auc_roc_weighted).mean()}, and {np.array(model_auc_roc_weighted).std()}\")\n",
    "        logger.info(f\"The mean and std of f1_macro are: {np.array(model_f1_macro).mean()}, and {np.array(model_f1_macro).std()}\")\n",
    "        logger.info(f\"The mean and std of f1_micro are: {np.array(model_f1_micro).mean()}, and {np.array(model_f1_micro).std()}\")\n",
    "        logger.info(f\"The mean and std of f1_weighted are: {np.array(model_f1_weighted).mean()}, and {np.array(model_f1_weighted).std()}\")"
   ],
   "id": "ed3f2b4d52a90ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model explanation",
   "id": "830a5feb50c9db30"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torchcam.utils import overlay_mask\n",
    "from torchvision.transforms.v2.functional import to_pil_image\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_grad_cam import GradCAM, HiResCAM, GradCAMPlusPlus, XGradCAM, EigenGradCAM, GradCAMElementWise\n",
    "import math\n",
    "from torch import nn\n",
    "import cv2\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, \\\n",
    "    preprocess_image\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "\n",
    "# only do XAI for DINO model\n",
    "logger.info(\"#####################################################################\")\n",
    "logger.info(f'Using model: {main_structure}')\n",
    "logger.info(\"#####################################################################\")\n",
    "\n",
    "xai_method = \"HiResCAM\" # user input: the XAI method\n",
    "set_num = 3 # users can choose the best hyper-parameter set based on the grid search\n",
    "dropout = 0.3 # in all-layer finetune, this can use the default value 0.3, but in linear probe, the dropout value of the best hyperparameter set should be entered by users. 0.3 or 0.0\n",
    "fold_idx = 1 # users can choose the best fold index within the best hyper-parameter set based on the performance of test set.\n",
    "logger.info(\"#####################################################################\")\n",
    "logger.info(f'Using hyper-parameter set: {set_num}, fold: {fold_idx}, dropout: {dropout}, XAI method: {xai_method}')\n",
    "logger.info(\"#####################################################################\")\n",
    "\n",
    "\n",
    "if main_structure.lower() == 'dino':\n",
    "    model = torch.hub.load('facebookresearch/dino:main', 'dino_vitb16', pretrained=True)\n",
    "    num_features = model.embed_dim\n",
    "elif main_structure.lower() == 'dinov2':\n",
    "    model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14', pretrained=True)\n",
    "    num_features = model.embed_dim\n",
    "elif main_structure.lower() == 'dinov3':\n",
    "    model = torch.hub.load(REPO_DINOV3, 'dinov3_vitb16', source='local', weights=WEIGHTS_DINOV3)\n",
    "    num_features = model.embed_dim\n",
    "elif main_structure.lower() == 'vit':\n",
    "    model = torch.hub.load('pytorch/vision', 'vit_b_16', pretrained=True)\n",
    "    model, num_features = replace_classifier(model)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "class ModifiedTestViT(nn.Module):\n",
    "    def __init__(self, base_model, in_features):\n",
    "        super(ModifiedTestViT, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.head = nn.Sequential(nn.Dropout(dropout),\n",
    "                                  nn.Linear(in_features, 2))  # modify the head from Identify to 2-class classification (Linear Layer) and add drop out (included in grid search)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # the features from ViT backbone (batch size, 768 (dim of class token))\n",
    "        features = self.base_model(x)\n",
    "        # pass the classification head\n",
    "        return self.head(features)\n",
    "\n",
    "\n",
    "model = ModifiedTestViT(model, num_features).to(device)\n",
    "if finetune:\n",
    "    logger.info(\"here is the XAI for all-layer finetune, without nucleus\") # change\n",
    "    model.load_state_dict(torch.load(main_structure + \"_all_layer_finetune_without_blue_best_model_parameter_\" + str(set_num) + \"_\" + str(fold_idx) + \".pth\")) # change\n",
    "    save_path = os.path.join(grad_cam_base_path, \"without_nucleus_all_layer_finetune_\" + main_structure + \"_\" + str(set_num) + \"_\" + str(fold_idx) + \"_\" + xai_method) # change\n",
    "else:\n",
    "    logger.info(\"here is the XAI for linear probe, without nucleus\") # change\n",
    "    model.load_state_dict(torch.load(main_structure + \"_linear_probe_without_blue_best_model_parameter_\" + str(set_num) + \"_\" + str(fold_idx) + \".pth\")) # change\n",
    "    save_path = os.path.join(grad_cam_base_path, \"without_nucleus_linear_probe_\" + main_structure + \"_\" + str(set_num) + \"_\" + str(fold_idx) + \"_\" + xai_method) # change\n",
    "model.eval()\n",
    "\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "last_block = model.base_model.blocks[-1]\n",
    "penultimate_block = model.base_model.blocks[-2]\n",
    "# target_layers = [penultimate_block.norm1, penultimate_block.norm2, last_block.norm1]\n",
    "target_layers = [last_block.norm1]\n",
    "\n",
    "def reshape_transform(tensor):\n",
    "    # get rid of cls token\n",
    "    if (tensor.size(1) - 1) != 196 and (tensor.size(1) - 1) != 256:\n",
    "        logger.info(\"here is using DINOv3, remove the register tokens!\")\n",
    "        height = int(math.sqrt(tensor.size(1) - 5)) # remove 1 [CLS] token and 4 register tokens\n",
    "        width = int(math.sqrt(tensor.size(1) - 5))\n",
    "        assert height * width == (tensor.size(1) - 5), \"the square root of input tensor is not integer!\"\n",
    "        result = tensor[:, 5:, :].reshape(tensor.size(0),\n",
    "                                      height, width, tensor.size(2))\n",
    "    else:\n",
    "        height = int(math.sqrt(tensor.size(1) - 1))\n",
    "        width = int(math.sqrt(tensor.size(1) - 1))\n",
    "        assert height * width == (tensor.size(1) - 1), \"the square root of input tensor is not integer!\"\n",
    "        result = tensor[:, 1:, :].reshape(tensor.size(0),\n",
    "                                      height, width, tensor.size(2))\n",
    "    # (1,14,14,768) or (1,16,16,768)\n",
    "    # put the channel in the second dimension\n",
    "    result = result.transpose(2, 3).transpose(1, 2)\n",
    "    return result\n",
    "\n",
    "cam = HiResCAM(model=model, target_layers=target_layers, reshape_transform=reshape_transform)\n",
    "\n",
    "for data in range(len(test_dataset[0])):\n",
    "    inputs = test_dataset[0][data][0]\n",
    "    inputs = inputs.to(device)\n",
    "    target_class = test_dataset[0][data][1]\n",
    "\n",
    "    input_tensor = inputs.unsqueeze(0).to(device)\n",
    "\n",
    "    input_image = to_pil_image(transform_inverse(input_tensor.squeeze(0)))\n",
    "\n",
    "    cam.batch_size = 32\n",
    "    activation_map = cam(input_tensor=input_tensor, targets=None, eigen_smooth = False) # use sum to calculate final cam\n",
    "\n",
    "    activation_map = activation_map[0, :]\n",
    "\n",
    "    overlay = overlay_mask(input_image, to_pil_image(activation_map, mode='F'), alpha=0.5)\n",
    "\n",
    "    outputs = cam.outputs\n",
    "    predicted_class = outputs.argmax(dim=1).item()\n",
    "    logger.info(f\"the image index is: {data}, the output is: {outputs}, the predicted and ground truth class are: {predicted_class} and {target_class}\")\n",
    "\n",
    "    # plot original and traditional Grad-CAM\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Original Image')\n",
    "    plt.imshow(input_image)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(xai_method)\n",
    "    plt.imshow(overlay)\n",
    "    plt.axis('off')\n",
    "\n",
    "    image_save_path = os.path.join(save_path, str(data) + \"_\" + str(test_dataset[0][data][1]) + \"_XAI.png\")\n",
    "    plt.savefig(image_save_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.title(xai_method)\n",
    "    plt.imshow(overlay)\n",
    "    plt.axis('off')\n",
    "\n",
    "    image_save_path = os.path.join(save_path, str(data) + \"_\" + str(test_dataset[0][data][1]) + \"_\" + xai_method + \".png\")\n",
    "    plt.savefig(image_save_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ],
   "id": "3d813e47fc5261f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "logging.shutdown()",
   "id": "6c88941e1ec9eb6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
