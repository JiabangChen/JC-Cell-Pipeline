{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time, os, sys\n",
    "from urllib.parse import urlparse\n",
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.patches import Polygon\n",
    "from urllib.parse import urlparse\n",
    "from cellpose import models, core, utils\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import exposure\n",
    "import cv2\n",
    "from skimage.transform import resize\n",
    "from training_toolbox import resize_image\n",
    "\n",
    "%matplotlib inline\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "mpl.rcParams['figure.dpi'] = 200\n",
    "\n",
    "# call logger_setup to have output of cellpose written\n",
    "from cellpose.io import logger_setup\n",
    "logger_setup();"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prepare whole-slide fluorescent microscopy images",
   "id": "26b60b82ed45a94a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# for segmentation visualization on more than 3 channel tiff, and to make sure the channel sequence is R G B Orange, actually use RGB format image as the reference image has better performance.\n",
    "channel_sequence = input(\"Please input the channel sequence of the reference image, and use spaces to separate them (e.g. R G B Orange): \").split(\" \")\n",
    "red_index, green_index, blue_index, orange_index = -1, -1, -1, -1\n",
    "for i in range(len(channel_sequence)):\n",
    "    if channel_sequence[i].lower() == 'orange':\n",
    "        orange_index = i\n",
    "    elif channel_sequence[i].lower() == 'r':\n",
    "        red_index = i\n",
    "    elif channel_sequence[i].lower() == 'g':\n",
    "        green_index = i\n",
    "    elif channel_sequence[i].lower() == 'b':\n",
    "        blue_index = i"
   ],
   "id": "a85b1a432c8ea7e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tifffile\n",
    "\n",
    "img = tifffile.imread(\"D:\\cell_formal\\OneDrive_2025-06-27\\Oscar_images\\BJ Ras\\\\type4-multi-stain (RGB)-3.tif\")\n",
    "# use tiffile to read the tif image, it can read one page with 3-channel RGB and 4 page with one\n",
    "# channel in each page.\n",
    "print(\"Original shape:\", img.shape)\n",
    "print(\"Original dtype:\", img.dtype)\n",
    "assert(img.dtype=='uint8')\n",
    "if img.shape[0] < 10:\n",
    "    img = np.moveaxis(img, 0, -1)  # (4, H, W) -> (H, W, 4)\n",
    "    print(\"After shape:\", img.shape)\n",
    "red_channel = img[:,:,red_index:red_index+1]\n",
    "green_channel = img[:,:,green_index:green_index+1]\n",
    "blue_channel = img[:,:,blue_index:blue_index+1]\n",
    "if orange_index != -1: # there is another orange channel apart from R G B.\n",
    "    orange_channel = img[:,:,orange_index:orange_index+1]\n",
    "    img = np.concatenate([red_channel, green_channel, blue_channel, orange_channel], axis=2)\n",
    "    print(\"The channel sequence has been modified to R G B and Orange\")\n",
    "else:\n",
    "    img = np.concatenate([red_channel, green_channel, blue_channel], axis=2)\n",
    "    print(\"The channel sequence has been modified to R G B\")\n",
    "merged_img = Image.fromarray(img) # this image is reference image, only used to train the Cellpose, it should be an RGB COLOR tif image, not 4-channel tif image"
   ],
   "id": "8cf2608b85cebbf9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "output_size = (4000, 1000)  # Adjust based on your CPU memory constraints. not too small, and the ratio between width and height should keep the same\n",
    "downsize_image, original_size = resize_image(merged_img, output_size)\n",
    "\n",
    "print(downsize_image.shape) # downsize_image is numpy, so the output shape is height x width\n",
    "print(original_size) # original size is the size of Image, so the output shape is width x height\n",
    "\n",
    "# Plot the downsized image\n",
    "plt.imshow(downsize_image[:,:,:3])\n",
    "plt.title('Downsize Image')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "6e9e2ae3083c79d4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pre-processing with CLAHE",
   "id": "e6efb878b9f27e29"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Apply adaptive histogram equalization\n",
    "equalized_image = exposure.equalize_adapthist(downsize_image[:,:,:3], clip_limit=0.02) # equalize_adapthist only accept an image with 3 channelï¼Œactually we need RGB COLOR tif file to do this, because the traditional tif file value is distributed in a narrow range, like [0,70], the contrast is low, so this equalize_adapthist cannot process well, but using RGB color in Fiji can normalize the pixel value to [0,255], the contrast is good, so this function works well\n",
    "\n",
    "# Plot the original and preprocessed images\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "axes[0].imshow(downsize_image[:,:,:3], cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(equalized_image, cmap='gray')\n",
    "axes[1].set_title('Equalized Image')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(equalized_image.shape)"
   ],
   "id": "8909d96bb7877c4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model training",
   "id": "84d49d275b63f024"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load the pre-trained Cellpose model\n",
    "model = models.Cellpose(model_type='cyto3')\n",
    "\n",
    "# Predict on the resized image\n",
    "masks, flows, styles, diams = model.eval(equalized_image, diameter=None, channels=[2, 3])\n",
    "print(masks.shape)\n",
    "\n",
    "# Generate outlines from the segmentation mask\n",
    "outlines = utils.outlines_list(masks)\n",
    "\n",
    "# Plot the downsized image with outlines\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(equalized_image, cmap='gray')\n",
    "\n",
    "for outline in outlines:\n",
    "    polygon = Polygon(outline, fill=False, edgecolor='red', linewidth=1)\n",
    "    plt.gca().add_patch(polygon)\n",
    "plt.title('Resized Image with Outlines')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "id": "b927930c388cff66"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Mask upsizing",
   "id": "908153ec0c3d404e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pil_image = Image.fromarray(masks)\n",
    "upsize_masks, original_size = resize_image(pil_image, (22656, 5594)) # based on the original size of the input image\n",
    "\n",
    "print(np.array(merged_img).shape)\n",
    "print(upsize_masks.shape)\n",
    "print(original_size)\n",
    "\n",
    "# Generate outlines from the segmentation mask\n",
    "outlines = utils.outlines_list(upsize_masks)\n",
    "\n",
    "# Plot the original image with outlines\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(img[:,:,:3], cmap='gray')\n",
    "for outline in outlines:\n",
    "    polygon = Polygon(outline, fill=False, edgecolor='red', linewidth=1)\n",
    "    plt.gca().add_patch(polygon)\n",
    "plt.title('Original Image with Outlines')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "id": "e5aaaab13f3951c4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Extracted Individual Cells, use a 3-channel RGB Color tif to train the model, but segment on a 4-channel 8-bit tif image (or we can still use 3-channel RGB, based on the case)",
   "id": "4283bf54adde8fa6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "channel_sequence = input(\"Please input the channel sequence of the image you want to segment, and use spaces to separate them (e.g. R G B Orange): \").split(\" \")\n",
    "red_index, green_index, blue_index, orange_index = -1, -1, -1, -1\n",
    "for i in range(len(channel_sequence)):\n",
    "    if channel_sequence[i].lower() == 'orange':\n",
    "        orange_index = i\n",
    "    elif channel_sequence[i].lower() == 'r':\n",
    "        red_index = i\n",
    "    elif channel_sequence[i].lower() == 'g':\n",
    "        green_index = i\n",
    "    elif channel_sequence[i].lower() == 'b':\n",
    "        blue_index = i"
   ],
   "id": "cd2601a5a83946e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tifffile\n",
    "\n",
    "img = tifffile.imread(\"D:\\cell_formal\\OneDrive_2025-06-27\\Oscar_images\\BJ Ras\\\\type4-multi-stain (RGB)-3.tif\")\n",
    "# use tiffile to read the tif image, it can read one page with 3-channel RGB and 4 page with one\n",
    "# channel in each page.\n",
    "print(\"Original shape:\", img.shape)\n",
    "print(\"Original dtype:\", img.dtype)\n",
    "assert(img.dtype=='uint8')\n",
    "if img.shape[0] < 10:\n",
    "    img = np.moveaxis(img, 0, -1)  # (4, H, W) -> (H, W, 4)\n",
    "    print(\"After shape:\", img.shape)\n",
    "red_channel = img[:,:,red_index:red_index+1]\n",
    "green_channel = img[:,:,green_index:green_index+1]\n",
    "blue_channel = img[:,:,blue_index:blue_index+1]\n",
    "if orange_index != -1: # there is another orange channel apart from R G B.\n",
    "    orange_channel = img[:,:,orange_index:orange_index+1]\n",
    "    img = np.concatenate([red_channel, green_channel, blue_channel, orange_channel], axis=2)\n",
    "    print(\"The channel sequence has been modified to R G B and Orange\")\n",
    "else:\n",
    "    img = np.concatenate([red_channel, green_channel, blue_channel], axis=2)\n",
    "    print(\"The channel sequence has been modified to R G B\")\n",
    "# this img is used to segment"
   ],
   "id": "b46c65a4f54af4b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create a directory to save individual cell images\n",
    "output_dir = 'type4\\\\3'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Find unique cells in the mask\n",
    "cell_ids = np.unique(upsize_masks)\n",
    "cell_ids = cell_ids[cell_ids != 0]  # Remove background (ID 0)\n",
    "\n",
    "for cell_id in cell_ids:\n",
    "    # Create a mask for the current cell\n",
    "    cell_mask = upsize_masks == cell_id\n",
    "\n",
    "    # Adjust the mask to match the image's shape\n",
    "    if orange_index != -1:\n",
    "        cell_mask_rgb = np.stack([cell_mask] * 4, axis=-1)\n",
    "    else:\n",
    "        cell_mask_rgb = np.stack([cell_mask] * 3, axis=-1)\n",
    "\n",
    "    # Extract the cell from the image using the mask\n",
    "    cell_img = img * cell_mask_rgb # use the real image which aims to segment\n",
    "\n",
    "    # Find the bounding box of the cell to crop the image\n",
    "    coords = np.argwhere(cell_mask)\n",
    "    y0, x0 = coords.min(axis=0)\n",
    "    y1, x1 = coords.max(axis=0) + 1  # slices are exclusive at the top\n",
    "\n",
    "    # Crop the cell image with bounding box\n",
    "    cell_img_cropped = cell_img[y0:y1, x0:x1]\n",
    "\n",
    "    # Save the cropped cell image\n",
    "    cell_filename = os.path.join(output_dir, f'cell_{cell_id}.tif')\n",
    "    tifffile.imwrite(cell_filename, cell_img_cropped)\n",
    "\n",
    "print(f'Individual cell images are saved in the directory: {output_dir}')"
   ],
   "id": "f513a95d3773d0fe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
